[{"pageContent":"INFO 2950: \n\nIntro to Data Science\n\n\nLecture 13\n\n2023-10-11\n\n1","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":1,"lines":{"from":1,"to":10}}}},{"pageContent":"Agenda\n\n1.\nOverfitting\n\n\n2.\nTrain / Test Split\n\n\n3.\nEvaluation Metrics\n\n\n\n\n2","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":2,"lines":{"from":1,"to":17}}}},{"pageContent":"“Training a model”: single variable\n\n●\nGiven a df with two columns, x and y\n\n\n●\nYou run regression y~x in Python\n\n\n●\nPython returns \nɑ\n-hat and  \nβ\n-hat\n\n\n●\nAre there problems with this?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":3,"lines":{"from":1,"to":20}}}},{"pageContent":"Overfitting: single variable\n\n●\nIt depends!  If you just want to describe the data \nthat you have, this is fine.","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":4,"lines":{"from":1,"to":5}}}},{"pageContent":"Overfitting: single variable\n\n●\nIt depends!  If you just want to describe the data \nthat you have, this is fine.\n\n\n●\nIf you’re trying to \ngeneralize your findings\n to “new \ndata”, what happens if the (x, y) values in your df \naren’t representative of the “new data”?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":5,"lines":{"from":1,"to":13}}}},{"pageContent":"Overfitting: single variable\n\n●\nIt depends!  If you just want to describe the data \nthat you have, this is fine.\n\n\n●\nIf you’re trying to generalize your findings to “new \ndata”, what happens if the (x, y) values in your df \naren’t representative of the “new data”?\n\n○\nYou make\n bad generalizations\n\n○\nThis is called \n“overfitting”\n to your existing data","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":6,"lines":{"from":1,"to":20}}}},{"pageContent":"Overfitting: which line is “better”?\n\nhttps://statisticsbyjim.com/regression/overfitting-regression-models/\n \n\nLine A\n\nSquiggle B\n\n琀\n琀","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":7,"lines":{"from":1,"to":11}}}},{"pageContent":"Overfitting: which line is “better”?\n\nhttps://statisticsbyjim.com/regression/overfitting-regression-models/\n \n\nLine A\n\nSquiggle B\n\nFor these specific points, \nSquiggle B might be the best \nfit, but when picking a model \nthat could generalize well, \nLine A is probably better.","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":8,"lines":{"from":1,"to":14}}}},{"pageContent":"Training data: multiple variables\n\n●\nGiven multiple x’s and one y, now we run a \nmultivariable regression\n\n\n●\nIs overfitting a problem in this case, too?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":9,"lines":{"from":1,"to":9}}}},{"pageContent":"●\nYes\n: overfitting in high dimensions is\n much \nmore likely\n\n\n●\nMany different input x’s \n→\n the model can pick \nup on more complexity, but then you get \nmodels adhering too much to the \ndata\n \ninstead of the underlying \nidea\n\nTraining data: multiple variables","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":10,"lines":{"from":1,"to":19}}}},{"pageContent":"Overfitting: multiple variables\n\nhttps://www.ibm.com/cloud/learn/overfitting\n \n\nOutput y (binary) represented by shape \n\nx\n1\n\nx\n2","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":11,"lines":{"from":1,"to":12}}}},{"pageContent":"Overfitting: multiple variables\n\nhttps://www.ibm.com/cloud/learn/overfitting\n \n\nOutput y (binary) represented by shape \n\nx\n1\n\nx\n1\n\nx\n1\n\nx\n2\n\nx\n2\n\nx\n2","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":12,"lines":{"from":1,"to":24}}}},{"pageContent":"How to overcome overfitting?\n\n●\n“\nFeature selection\n”: identify the most important \ncovariates (inputs) for your model and only include \nthose.  This allows you to reduce the number of \ndimensions of your data\n\n\n●\nUse a \ntrain / test split\n\n\n●\nRegularization\n\n○\nMuch later in the class","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":13,"lines":{"from":1,"to":21}}}},{"pageContent":"Feature selection review\n\n●\nChoose covariates that... \n\n\n○\nmake sense given domain expertise\n\n\n○\naren’t redundant\n (i.e., \naren’t collinear\n and \ndon’t overfit\n the data)\n\n\n○\nallow you (with transformation) to get \nrandom-looking residual plots","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":14,"lines":{"from":1,"to":22}}}},{"pageContent":"How to overcome overfitting?\n\n●\n“\nFeature selection\n”: identify the most important \ncovariates (inputs) for your model and only include \nthose.  This allows you to reduce the number of \ndimensions of your data\n\n\n●\nUse a \ntrain / test split\n\n\n●\nRegularization\n\n○\nMuch later in the class","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":15,"lines":{"from":1,"to":21}}}},{"pageContent":"Train / test split\n\n●\nTrain/test split: \nbefore you do anything, \nrandomly \nsplit \nyour df’s data rows into two subsets\n\n○\nTrain set: 70% of your data\n\n○\nTest set: 30% of your data\n\n\n●\nThe 70/30 ratio not set in stone, just a rule of thumb\n\n\n●\nOften you will see a third dataset called the “validation \nset” that could yield a ~70/15/15 train/val/test split\n\n16","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":16,"lines":{"from":1,"to":25}}}},{"pageContent":"Train / test split \nfor overfitting?\n\n●\nLook at only your training set (a random 70% of your \ndata) when building your model\n\n\n●\nThen confirm it generalizes well to the other 30% of \nyour data (the test set)!\n\n○\nThis step helps you confirm that you’re not overfitting\n\n\n\n\n17","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":17,"lines":{"from":1,"to":19}}}},{"pageContent":"Train / test split \nfor overfitting?\n\n●\nLook at only your training set (a random 70% of your \ndata) when building your model\n\n\n●\nThen confirm it generalizes well to the other 30% of \nyour data (the test set)!\n\n○\nThis step helps you confirm that you’re not overfitting\n\n○\nValidation sets are nice because you can check for \noverfitting on just 15% of the data, and if you’re overfitting, \nthen you can keep fixing your model until you’re ready to \ncheck the final 15% of your data (the test set)\n\n\n\n\n18","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":18,"lines":{"from":1,"to":25}}}},{"pageContent":"19\n\nhttps://pbs.twimg.com/media/DdkUUTMV4AAsohU.jpg\n \n\nThink, pair, share\n: explain the meme","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":19,"lines":{"from":1,"to":7}}}},{"pageContent":"20\n\nhttps://pbs.twimg.com/media/DdkUUTMV4AAsohU.jpg\n \n\nThink, pair, share: explain the meme\n\nThis “model” was only \ntrained\n on side \nsleepers! It works \ngreat for them, but is a \nterrible model if \ntested\n \non back sleepers or \npeople who roll around","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":20,"lines":{"from":1,"to":17}}}},{"pageContent":"21\n\nhttps://pbs.twimg.com/media/DdkUUTMV4AAsohU.jpg\n \n\nThink, pair, share: explain the meme\n\nThis is why it’s important \nto represent a  diversity \nof sleeping positions in \nboth the \ntraining data\n \nand also the \ntest set","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":21,"lines":{"from":1,"to":15}}}},{"pageContent":"22\n\nhttps://www.youtube.com/watch?v=DQWI1kvmwRg","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":22,"lines":{"from":1,"to":3}}}},{"pageContent":"How to generate a train / test split?\n\nhttps://builtin.com/data-science/train-test-split\n \n\n23\n\nStep 0. \nFigure out what data \nyou need to run your model\n\ny ~ x\n1\n + x\n2\n + x\n3\n + x\n4\n + x\n5","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":23,"lines":{"from":1,"to":21}}}},{"pageContent":"How to generate a train / test split?\n\nhttps://builtin.com/data-science/train-test-split\n \n\n24\n\nStep 0. \nFigure out what data \nyou need to run your model\n\ny ~ x\n1\n + x\n2\n + x\n3\n + x\n4\n + x\n5\n\nHow many columns \nat minimum\n should there be in \nyour dataframe, in order to fit this regression?\n\n琀\n琀","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":24,"lines":{"from":1,"to":29}}}},{"pageContent":"How to generate a train / test split?\n\nhttps://builtin.com/data-science/train-test-split\n \n\n25\n\nStep 0. \nFigure out what data \nyou need to run your model\n\ny ~ x\n1\n + x\n2\n + x\n3\n + x\n4\n + x\n5\n\nAnswer: at least 5 columns for each of the x’s plus 1 \ncolumn for the y, so there should be at least 6 total \ncolumns present in your df to run this linear \nregression (without needing to reshape first)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":25,"lines":{"from":1,"to":26}}}},{"pageContent":"How to generate a train / test split?\n\nhttps://builtin.com/data-science/train-test-split\n \n\n26\n\nStep 1. \nGiven your df, use a \nrandomizer to assign 70% of \nyour rows to the “train set” \nand 30% of your rows to the \n“test set”\n\nStill one df, just visually split to show \nthe difference between x’s and y","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":26,"lines":{"from":1,"to":16}}}},{"pageContent":"How to generate a train / test split?\n\nhttps://builtin.com/data-science/train-test-split\n \n\n27\n\nStep 1. \nGiven your df, use a \nrandomizer to assign 70% of \nyour rows to the “train set” \nand 30% of your rows to the \n“test set”\n\nWe’ve identified that these three \nrows will go into our test set","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":27,"lines":{"from":1,"to":16}}}},{"pageContent":"How to generate a train / test split?\n\nhttps://builtin.com/data-science/train-test-split\n \n\n28\n\nStep 2. \nSplit your df into \ntwo separate df’s based on \nrandomized values\n\nWe’ve identified that these three \nrows will go into our test set","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":28,"lines":{"from":1,"to":14}}}},{"pageContent":"How to generate a train / test split?\n\nhttps://builtin.com/data-science/train-test-split\n \n\n29\n\nStep 2. \nSplit your df into \ntwo separate df’s based on \nrandomized values\n\nWe’ve identified that these three \nrows will go into our test set\n\nTest set (1 dataframe \nwith 3 rows, 6 columns)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":29,"lines":{"from":1,"to":17}}}},{"pageContent":"How to generate a train / test split?\n\nhttps://builtin.com/data-science/train-test-split\n \n\n30\n\nStep 2. \nSplit your df into \ntwo separate df’s based on \nrandomized values\n\nThe other seven rows go to the \n“train set”\n\nTest set\n\nTrain set \n(1 df, \n\n7 rows, \n\n6 cols)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":30,"lines":{"from":1,"to":23}}}},{"pageContent":"How to generate a train / test split?\n\nhttps://builtin.com/data-science/train-test-split\n \n\n31\n\nStep 2. \nSplit your df into \ntwo separate df’s based on \nrandomized values\n\nTest set\n\nTrain set","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":31,"lines":{"from":1,"to":15}}}},{"pageContent":"Four components\n generated\n\nhttps://builtin.com/data-science/train-test-split\n \n\n32\n\nStep 2. \nSplit your df into \ntwo separate df’s based on \nrandomized values\n\nTest set\n\nTrain set","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":32,"lines":{"from":1,"to":16}}}},{"pageContent":"Four components\n generated\n\nhttps://builtin.com/data-science/train-test-split\n \n\n33\n\nStep 2. \nSplit your df into \ntwo separate df’s based on \nrandomized values\n\nTest set\n\nTrain set","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":33,"lines":{"from":1,"to":16}}}},{"pageContent":"●\nfrom sklearn.model_selection import train_test_split\n\n\n●\nX_train, X_test, y_train, y_test = train_test_split(X, \ny, test_size = 0.3, random_state = 42)\n\n34\n\nGenerate train/test in Python","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":34,"lines":{"from":1,"to":11}}}},{"pageContent":"●\nfrom sklearn.model_selection import train_test_split\n\n\n●\nX_train, X_test, y_train, y_test = train_test_split(X, \ny, test_size = 0.3, random_state = 42)\n\n\n\n35\n\nGenerate train/test in Python","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":35,"lines":{"from":1,"to":13}}}},{"pageContent":"●\nfrom sklearn.model_selection import train_test_split\n\n\n●\nX_train, X_test, y_train, y_test = train_test_split(X,\n\ny, test_size = 0.3, random_state = 42)\n\n\n\nInputs to train_test_split are X \n(can be multiple columns of x’s) \nand y (one column)\n\n36\n\nGenerate train/test in Python","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":36,"lines":{"from":1,"to":18}}}},{"pageContent":"●\nfrom sklearn.model_selection import train_test_split\n\n\n●\nX_train, X_test, y_train, y_test = train_test_split(X, \ny, test_size = 0.3, random_state = 42)\n\n\n\n70% train set, 30% test set split\n\n37\n\nGenerate train/test in Python","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":37,"lines":{"from":1,"to":15}}}},{"pageContent":"Generate train/test in Python\n\n●\nfrom sklearn.model_selection import train_test_split\n\n\n●\nX_train, X_test, y_train, y_test = train_test_split(X, \ny, test_size = 0.3, random_state = 42)\n\nset seed to a specific integer so you \ncan reproduce your “random” results\n\n38","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":38,"lines":{"from":1,"to":14}}}},{"pageContent":"●\nfrom sklearn.model_selection import train_test_split\n\n\n●\nX_train, X_test, y_train, y_test = train_test_split(X, \ny, test_size = 0.3, random_state = 42)\n\n\n\noutput: 4 different datasets \n\n39\n\nGenerate train/test in Python","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":39,"lines":{"from":1,"to":15}}}},{"pageContent":"Pros/cons of train/test split?\n\n●\nPros of splitting your data:\n\n○\nBetter out-of-sample generalizability\n\n○\nConfirmation that you’re not overfitting across variables\n\n○\nUsually results in a more meaningful interpretation\n\n\n●\nCons of splitting your data:\n\n○\nLess training data means your initial model might not be as \naccurate; this isn’t great if you’re \ndefinitely\n \nreally truly \nnot \ntrying to make broader generalizations (\nrare\n)\n\n40","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":40,"lines":{"from":1,"to":30}}}},{"pageContent":"What do you do with train / test sets?\n\nhttps://builtin.com/data-science/train-test-split\n \n\n41\n\nTest set\n\nTrain set","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":41,"lines":{"from":1,"to":10}}}},{"pageContent":"What do you do with train / test sets?\n\nhttps://builtin.com/data-science/train-test-split\n \n\n42\n\nTest set\n\nTrain set\n\ne.g. regression","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":42,"lines":{"from":1,"to":12}}}},{"pageContent":"●\nStep 1\n: experiment with your regression on your training set. \n \nMake any adjustments you need to here\n (e.g. try different \nmodels, transformations, etc.)\n\nhttps://builtin.com/data-science/train-test-split\n \n\n43\n\nWhat do you do with train / test sets?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":43,"lines":{"from":1,"to":14}}}},{"pageContent":"●\nStep 1\n: experiment with your regression on your training set. \n \nMake any adjustments you need to here (e.g. try different \nmodels, transformations, etc.)\n\nhttps://builtin.com/data-science/train-test-split\n \n\n44\n\nWhat do you do with train / test sets?\n\nmodel = LinearRegression().fit(X_train,y_train)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":44,"lines":{"from":1,"to":15}}}},{"pageContent":"●\nStep 2\n: make predictions using the train set only\n\nhttps://builtin.com/data-science/train-test-split\n \n\n45\n\nWhat do you do with train / test sets?\n\nmodel = LinearRegression().fit(X_train,y_train)\n\ny_hat_train = model.predict(X_train)\n\nWhy do we do this? \n Because we want to compare our true y values \n(y_train) to the values predicted by our model (y_hat_train).\n\nDetails: stay tuned for Step 4!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":45,"lines":{"from":1,"to":20}}}},{"pageContent":"●\nStep 1\n: fit model on train set\n\n●\nStep 2\n: predict y-hats from using train set model on X_train\n\n\n●\nStep 3\n: predict y-hats from using train set model on \ntest set\n\n\nhttps://builtin.com/data-science/train-test-split\n \n\n46\n\nWhat do you do with train / test sets?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":46,"lines":{"from":1,"to":21}}}},{"pageContent":"●\nStep 1\n: fit model on train set\n\n●\nStep 2\n: predict y-hats from using train set model on X_train\n\n\n●\nStep 3\n: predict y-hats from using train set model on \ntest set\n\n\nhttps://builtin.com/data-science/train-test-split\n \n\n47\n\nWhat do you do with train / test sets?\n\ny_hat_test = model.predict(\n______\n)\n\n琀\n琀","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":47,"lines":{"from":1,"to":28}}}},{"pageContent":"●\nStep 1\n: fit model on train set\n\n●\nStep 2\n: predict y-hats from using train set model on X_train\n\n\n●\nStep 3\n: predict y-hats from using train set model on \ntest set\n\n\nhttps://builtin.com/data-science/train-test-split\n \n\n48\n\nWhat do you do with train / test sets?\n\ny_hat_test = model.predict(\nX_test\n)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":48,"lines":{"from":1,"to":25}}}},{"pageContent":"●\nStep 1\n: fit model on train set\n\n●\nStep 2\n: predict y-hats from using train set model on X_train\n\n\n●\nStep 3\n: predict y-hats from using train set model on \ntest set\n\n\n\nhttps://builtin.com/data-science/train-test-split\n \n\n49\n\nWhat do you do with train / test sets?\n\nWhat is the \n“true” value of y \nthat we want to \ncompare \ny_hat_test to?\n\ny_hat_test = model.predict(\nX_test\n)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":49,"lines":{"from":1,"to":32}}}},{"pageContent":"●\nStep 1\n: fit model on train set\n\n●\nStep 2\n: predict y-hats from using train set model on X_train\n\n\n●\nStep 3\n: predict y-hats from using train set model on \ntest set\n\n\n\nhttps://builtin.com/data-science/train-test-split\n \n\n50\n\nWhat do you do with train / test sets?\n\ny_test is the true \noutput when the \ninput is X_test \n(they are both in \nthe test set)\n\ny_hat_test = model.predict(\nX_test\n)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":50,"lines":{"from":1,"to":32}}}},{"pageContent":"●\nStep 1\n: fit model on train set\n\n●\nStep 2\n: predict y-hats from using train set model on X_train\n\n\n●\nStep 3\n: predict y-hats from using train set model on \ntest set\n\n\n\nhttps://builtin.com/data-science/train-test-split\n \n\n51\n\nWhat do you do with train / test sets?\n\nNotice we use the \ntrain set model \nwhen predicting \nthe test set \nŷ\n\ny_hat_test = \nmodel\n.predict(X_test)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":51,"lines":{"from":1,"to":32}}}},{"pageContent":"Why do you predict both train and test \nset y-hats with the same ML model?\n\nhttps://builtin.com/data-science/train-test-split\n \n\n52\n\nTest set\n\nTrain set\n\ne.g. regression","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":52,"lines":{"from":1,"to":13}}}},{"pageContent":"https://twitter.com/deeplearningai_/status/1242160243204689920\n \n\n53\n\nThink, pair, share\n: why don’t we want to \npredict y_hat_test by fitting a new model \non the test set?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":53,"lines":{"from":1,"to":9}}}},{"pageContent":"https://twitter.com/deeplearningai_/status/1242160243204689920\n \n\n54\n\nWhy don’t we want to predict y_hat_test \nby \nfitting a new model on the test set?\n\nWe’d be 1. training a \nmodel on an even \nsmaller dataset (only \n30% of the data – so \nprobably less \ngeneralizable) and 2. \nartificially reporting \n“good” results because \ny_hat_test should be \npretty accurate if you \ntrained on the test set!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":54,"lines":{"from":1,"to":20}}}},{"pageContent":"●\nStep 1\n: fit model on train set\n\n●\nStep 2\n: predict y-hats from using train set model on X_train\n\n●\nStep 3\n: predict y-hats from using train set model on test set\n\n\n●\nStep 4:\n calculate “\nevaluation metrics\n”\n\n○\nFor now, think of this as “accuracy” of the model\n\n○\nEvaluate accuracy metrics on the \ntrain\n set \n\n○\nEvaluate accuracy metrics on the \ntest\n set \n\n\n55\n\nComparing evaluation metrics","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":55,"lines":{"from":1,"to":36}}}},{"pageContent":"●\nStep 4:\n calculate “\nevaluation metrics\n” on...\n\n○\nTrain set\n:\n\n■\nCompare \ny_hat_train\n to \ny_train\n\n■\nGives you a sense of whether your model is good on \nyour train set only\n\n\n○\nTest set:\n\n■\nCompare \ny_hat_test\n to \ny_test\n\n■\nGives you a good sense of how your model would \ngeneralize to “other” data \n(are you overfitting?)\n\n\n56\n\nComparing evaluation metrics","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":56,"lines":{"from":1,"to":39}}}},{"pageContent":"Danger zone: your \nmodel might look \n“good”, but \nactually \nbe overfitting\n\n57\n\nhttps://9gag.com/gag/aOYo6Ly","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":57,"lines":{"from":1,"to":9}}}},{"pageContent":"Match answers to the grid\n\n●\nWhat does it mean if...\n\n\n\n\n\n\nTrain set metrics “bad”\n\n      \n\n     Train set metrics “good”\n\nTest  metrics “bad”\n\nTest metrics “good”\n\n58\n\n琀\n琀\n \n\nKeep experimenting with \nyour regression model – \nthe good test set metrics \nare a fluke!\n\nLGTM\n\nKeep experimenting with \nyour regression model – it \ndoesn’t seem to do well \non any data!\n\nYour model isn’t \ngeneralizing well to \nout-of-sample data. \nFigure out how to fix this \nin your model!\n\nA\n\nB\n\nC\n\nD\n\n?\n\n?\n\n?\n\n?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":58,"lines":{"from":1,"to":59}}}},{"pageContent":"Match answers to the grid\n\n●\nWhat does it mean if...\n\n\nTrain set metrics “bad”\n\n      \n\n     Train set metrics “good”\n\nTest  metrics “bad”\n\nTest metrics “good”\n\n59\n\nKeep experimenting with \nyour regression model – \nthe good test set metrics \nare a fluke!\n\nLGTM\n\nKeep experimenting with \nyour regression model – it \ndoesn’t seem to do well \non any data!\n\nYour model isn’t \ngeneralizing well to \nout-of-sample data. \nFigure out how to fix this \nin your model!\n\nA\n\nB\n\nC\n\nD\n\n\n\n\n\nA\n\nB\n\nC\n\nD","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":59,"lines":{"from":1,"to":55}}}},{"pageContent":"Match answers to the grid\n\n●\nWhat does it mean if...\n\n\nTrain set metrics “bad”\n\n      \n\n     Train set metrics “good”\n\nTest  metrics “bad”\n\nTest metrics “good”\n\n60\n\n\n\n\n\nKeep experimenting with \nyour regression model – the \ngood test set metrics are a \nfluke!\n\nKeep experimenting with \nyour regression model – it \ndoesn’t seem to do well \non any data!\n\nLGTM\n\nYour model isn’t \ngeneralizing \nwell to out-of-sample data. \nFigure out how to fix this in \nyour model!\n\nStraightforward \ncases where either \nboth results are \ngood, or both results \nare bad","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":60,"lines":{"from":1,"to":45}}}},{"pageContent":"Match answers to the grid\n\n●\nWhat does it mean if...\n\n\nTrain set metrics “bad”\n\n      \n\n     Train set metrics “good”\n\nTest  metrics “bad”\n\nTest metrics “good”\n\n61\n\n\n\n\n\nKeep experimenting with \nyour regression model – the \ngood test set metrics are a \nfluke! \n(or, you accidentally \ntrained on the test set)\n\nKeep experimenting with \nyour regression model – it \ndoesn’t seem to do well \non any data!\n\nLGTM\n\nYour model isn’t \ngeneralizing \nwell to out-of-sample data. \nFigure out how to fix this in \nyour model!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":61,"lines":{"from":1,"to":41}}}},{"pageContent":"Match answers to the grid\n\n●\nWhat does it mean if...\n\n\nTrain set metrics “bad”\n\n      \n\n     Train set metrics “good”\n\nTest  metrics “bad”\n\nTest metrics “good”\n\n62\n\n\n\n\n\nKeep experimenting with \nyour regression model – the \ngood test set metrics are a \nfluke! \n(or, you accidentally \ntrained on the test set)\n\nKeep experimenting with \nyour regression model – it \ndoesn’t seem to do well \non any data!\n\nLGTM\n\nYour model isn’t \ngeneralizing \nwell to out-of-sample data. \nFigure out how to fix this in \nyour model!\n\nThe “overfitting” case!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":62,"lines":{"from":1,"to":43}}}},{"pageContent":"63\n\nYou should never ignore \nthe test set in an \nattempt to get good \naccuracy!\n\nhttps://twitter.com/deeplearningai_/status/1375100156186611712","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":63,"lines":{"from":1,"to":8}}}},{"pageContent":"Takeaways: reg evaluation\n\n●\nUse a train/test split if you want your model to be \ngeneralizable (~70/30%)\n\n\n●\nDon’t peek at the test set until you’re ready to do a final \nconfirmation that your model is generalizable\n\n○\nTrain set evaluation: compare y_hat_train to y_train\n\n○\nTest set evaluation: compare y_hat_test to y_test\n\n64","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":64,"lines":{"from":1,"to":18}}}},{"pageContent":"Caution: train/test\n\n●\nNeed to make sure your train/test sets have similar \ndistributions\n\n\n●\nNeed to be careful if you have time series data (can’t \njust randomly pick different times!)\n\n\n●\nWhat if you just get lucky with your train set choice?\n\n\n●\nWe’ll address these + discuss cross validation in a \nfuture lecture\n\n65","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":65,"lines":{"from":1,"to":21}}}},{"pageContent":"1 minute break & attendance\n\n66\n\ntinyurl.com/z5wm2vcw","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":66,"lines":{"from":1,"to":5}}}},{"pageContent":"67\n\nMotivation: I want to be able to numerically find \nthat the left/right model is good/bad.\n\nhttps://www.ibm.com/cloud/learn/overfitting","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":67,"lines":{"from":1,"to":6}}}},{"pageContent":"68\n\nTrain metrics good\n\nTest metrics bad\n\nTrain metrics good\n\nTest metrics good\n\nhttps://www.ibm.com/cloud/learn/overfitting","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":68,"lines":{"from":1,"to":11}}}},{"pageContent":"69\n\nTrain metrics good\n\nTest metrics bad\n\nhttps://mobile.twitter.com/rstatsmemes","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":69,"lines":{"from":1,"to":7}}}},{"pageContent":"Evaluating Regressions\n\n●\nHow do we know if our regressions are \n\nany good?\n\n\n○\nChecking residual plots, correlation \nmatrices for inputs, interaction plots, etc.\n\n70\n\nhttps://www.facebook.com/RegressiveRegressionMemesForHeteroskedasticTeens/","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":70,"lines":{"from":1,"to":15}}}},{"pageContent":"Evaluating Regressions\n\n●\nHow do we know if our regressions are \n\nany good?\n\n\n○\nChecking residual plots, correlation \nmatrices for inputs, interaction plots, etc.\n\n\n○\nEvaluation metrics\n\n71","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":71,"lines":{"from":1,"to":17}}}},{"pageContent":"What is R\n2\n?\n\n72\n\n●\nR\n2\n  = Explained Variation / Total Variation\n\n\n●\nSummarizes the % variation in the output that is \nexplainable by the regression model\n\n\n●\nR\n2\n is between 0 to 1, we generally want our \nmodels to have higher R\n2\n \n\nhttps://library.virginia.edu/data/articles/is-r-squared-useless","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":72,"lines":{"from":1,"to":26}}}},{"pageContent":"Reasons to not use R\n2\n\n73\n\n●\nR\n2\n can be low even when the model is correct\n\n○\nE.g., when variance increases, the R\n2\n value goes to 0\n\n\n●\nR\n2\n can be high even when the model is wrong\n\n○\nE.g., non-linear data\n\n\n\nhttps://library.virginia.edu/data/articles/is-r-squared-useless","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":73,"lines":{"from":1,"to":27}}}},{"pageContent":"Reasons to not use R\n2\n\n74\n\n●\nR\n2\n can be low even when the model is correct\n\n○\nE.g., when variance increases, the R\n2\n value goes to 0\n\n\n●\nR\n2\n can be high even when the model is wrong\n\n○\nE.g., non-linear data\n\n\n●\nR\n2\n can get worse if you keep your model the \nsame, but change the range of x, or use \ntransformations of y\n\n\n●\nR\n2\n is symmetric between x and y\n\nhttps://library.virginia.edu/data/articles/is-r-squared-useless","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":74,"lines":{"from":1,"to":39}}}},{"pageContent":"Use R\n2\n with \nextreme caution\n\n75\n\n●\nIt’s relatively uncommon for data science \npractitioners to use R\n2\n in many real-world \napplications\n\n\n●\nIf you \nreally must\n report R\n2\n, use the \nadjusted \nR\n2\n, \nwhich at least accounts for having multiple inputs \n(regular R\n2\n increases in # inputs x)\n\nhttps://library.virginia.edu/data/articles/is-r-squared-useless\n \n\nhttps://www.listendata.com/2014/08/adjusted-r-squared.html","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":75,"lines":{"from":1,"to":34}}}},{"pageContent":"What to use if not R\n2\n?\n\n76\n\n●\nThere are lots of other \nevaluation metrics\n to use\n\n\n○\nMore common in practice\n\n\n○\nBetter for doing model selection of linear \n(and nonlinear) regressions, e.g. telling you if \nyou’re overfitting","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":76,"lines":{"from":1,"to":20}}}},{"pageContent":"Recall that...\n\n●\nWhat does it mean if...\n\n\n\n\n\n\nTrain set metrics “bad”\n\n      \n\n     Train set metrics “good”\n\nTest  metrics “bad”\n\nTest metrics “good”\n\nKeep experimenting with \nyour regression model – \nthe good test set metrics \nare a fluke!\n\nKeep experimenting with \nyour regression model – it \ndoesn’t seem to do well \non any data!\n\nLGTM\n\n77\n\nYour model isn’t \ngeneralizing \nwell to out-of-sample data. \nFigure out how to fix this in \nyour model!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":77,"lines":{"from":1,"to":39}}}},{"pageContent":"●\nHow do you quantify your evaluation metrics?\n\n\n○\nDepends on whether your y is:\n\n\n■\nNumeric variable (non-binary)\n\n■\nBinary variable\n\n\n○\nIntuition: metric should be related to residuals, \nso big error \n→\n “bad” metric \n\n\n78\n\nWhat does “good” and “bad” mean??","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":78,"lines":{"from":1,"to":25}}}},{"pageContent":"79\n\nNomenclature for these slides\n\nGeneral case\n\n“y_true”,  “y\ni\n”\n\n“y_hat”, “ŷ\ni\n”\n\nTrain set\n\ny_train\n\ny_hat_train\n\nTest set\n\ny_test\n\ny_hat_test","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":79,"lines":{"from":1,"to":25}}}},{"pageContent":"80\n\nNomenclature for these slides\n\nGeneral case\n\n“y_true”,  “y\ni\n”\n\n“y_hat”, “ŷ\ni\n”\n\nTrain set\n\ny_train\n\ny_hat_train\n\nTest set\n\ny_test\n\ny_hat_test\n\nWe want to make \nthis comparison","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":80,"lines":{"from":1,"to":28}}}},{"pageContent":"81\n\nNomenclature for these slides\n\nGeneral case\n\n“y_true”,  “y\ni\n”\n\n“y_hat”, “ŷ\ni\n”\n\nTrain set\n\ny_train\n\ny_hat_train\n\nTest set\n\ny_test\n\ny_hat_test\n\nWe also want to \nmake this \ncomparison","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":81,"lines":{"from":1,"to":29}}}},{"pageContent":"82\n\nNomenclature for these slides\n\nGeneral case\n\n“y_true”,  “y\ni\n”\n\n“y_hat”, “ŷ\ni\n”\n\nTrain set\n\ny_train\n\ny_hat_train\n\nTest set\n\ny_test\n\ny_hat_test\n\nWhen providing \nformulas in these \nslides, we’ll \ngeneralize to these","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":82,"lines":{"from":1,"to":30}}}},{"pageContent":"If our y’s are numerical non-binary\n\n●\nMean Squared Error (MSE)\n\n\n●\nRoot Mean Squared Error (RMSE)\n\n\n \n√MSE\n\n\n\n\n●\nMean Absolute Error (MAE)\n\n\n●\nMean Absolute Percent Error (MAPE)\n\n83","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":83,"lines":{"from":1,"to":24}}}},{"pageContent":"If our y’s are numerical non-binary\n\n●\nMean Squared Error (MSE)\n\n\n●\nRoot Mean Squared Error (RMSE)\n\n\n \n√MSE\n\n\n\n\n●\nMean Absolute Error (MAE)\n\n\n●\nMean Absolute Percent Error (MAPE)\n\n84\n\nAll 4 of these \nmetrics are \noften used in \nthe real world!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":84,"lines":{"from":1,"to":29}}}},{"pageContent":"If our y’s are numerical non-binary\n\n●\nMean Squared Error (MSE)\n\n\n●\nRoot Mean Squared Error (RMSE)\n\n\n \n√MSE\n\n\n\n\n●\nMean Absolute Error (MAE)\n\n\n●\nMean Absolute Percent Error (MAPE)\n\n85\n\nAll based on residuals!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":85,"lines":{"from":1,"to":26}}}},{"pageContent":"Numerical prediction metrics in Python\n\n●\nfrom sklearn.metrics import mean_squared_error, \nmean_absolute_error, mean_absolute_percentage_error \n\n\n●\nmse = mean_squared_error(y_true,y_hat)\n\n●\nrmse = np.sqrt(mse)\n\n●\nmae = mean_absolute_error(y_true,y_hat)\n\n●\nmape = mean_absolute_percentage_error(y_true,y_hat)\n\n86","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":86,"lines":{"from":1,"to":20}}}},{"pageContent":"●\nStep 1\n: fit model on train set\n\n●\nStep 2\n: predict y-hats from using train set model on X_train\n\n●\nStep 3\n: predict y-hats from using train set model on \ntest set\n\n\n●\nStep 4:\n calculate “\nevaluation metrics\n”\n\n○\nFor now, think of this as “accuracy” of the model\n\n○\nEvaluate “accuracy” metrics on the train set \n\n○\nEvaluate “accuracy” metrics on the test set \n\n\n87\n\nComparing evaluation metrics","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":87,"lines":{"from":1,"to":33}}}},{"pageContent":"Make sure your inputs are what you really \nwant (overall, train set only, test set only)\n\n●\nfrom sklearn.metrics import mean_squared_error, \nmean_absolute_error, mean_absolute_percentage_error \n\n\n●\nmse = mean_squared_error(\ny_true,y_hat\n)\n\n●\nrmse = np.sqrt(mse)\n\n●\nmae = mean_absolute_error(\ny_true,y_hat\n)\n\n●\nmape = mean_absolute_percentage_error(\ny_true,y_hat\n)\n\n88","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":88,"lines":{"from":1,"to":27}}}},{"pageContent":"If our y’s are binary\n\n●\nThere are just a few very common metrics (stay \ntuned in three slides!)\n\n\n●\nBut to understand them, we have to think more \ncarefully about 0’s and 1’s \n\n89","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":89,"lines":{"from":1,"to":12}}}},{"pageContent":"Binary classification outcomes\n\n\n\n\n\n\n      Model predicts 1\n\n      \n\n     \n\nModel predicts 0\n\n          True value is 0\n\n True value is 1\n\n“Given this item’s \ncustomer review \nand price, do I \npredict that it’s a \nnose pack?”\n\n90","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":90,"lines":{"from":1,"to":26}}}},{"pageContent":"True positive\n\nCorrect prediction\n\nFalse negative\n\n\nFalse positive\n\nTrue negative\n\nCorrect prediction\n\n      Model predicts 1\n\n      \n\n     \n\nModel predicts 0\n\n          True value is 0\n\n True value is 1\n\n91\n\nBinary classification outcomes\n\n“Given this item’s \ncustomer review \nand price, do I \npredict that it’s a \nnose pack?”","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":91,"lines":{"from":1,"to":34}}}},{"pageContent":"https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n \n\n(Lots of options for classification)\n\n92","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":92,"lines":{"from":1,"to":6}}}},{"pageContent":"False positives vs false negatives\n\n●\nWhich metric do we care more about?\n\n○\nDepends on the application!\n\n\n●\nSometimes you want to prioritize minimizing fp \nover fn, and sometimes vice versa\n\n○\nIt can be very difficult to find a method that \nminimizes both – sometimes you must make \na trade-off!\n\n93","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":93,"lines":{"from":1,"to":19}}}},{"pageContent":"●\nIt’s Halloween and some annoying kids want to \negg your house without causing damage to your \nhouse.  They use an “egg classifier” for whether \nan egg-shaped item is an egg (egg=1, low \ndamage \nto house) or a rock (egg=0, high damage to \nhouse).\n\n○\nDo the kids care more about fp or fn?\n\n94\n\nhttps://towardsdatascience.com/false-positives-vs-false-negatives-4184c2ff941a\n \n\nhttps://www.reddit.com/r/mildlyinteresting/com\nments/5uvn8r/i_collect_rocks_that_look_like_\neggs/\n \n\n琀\n琀\n \n\nFalse positives or false negatives?\n\ntp\n\nfn\n\nfp\n\ntn\n\n   \nŷ\n=1      \nŷ\n=0\n\n y=0     y=1","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":94,"lines":{"from":1,"to":43}}}},{"pageContent":"False positives or false negatives?\n\n●\nIt’s Halloween and some annoying kids want to \negg your house without causing damage to your \nhouse.  They use an “egg classifier” for whether \nan egg-shaped item is an egg (egg=1, low \ndamage \nto house) or a rock (egg=0, high damage to \nhouse).\n\n○\nIf the kids think something is an egg but it’s actually a rock, \nthat’s bad! If they think something is a rock and don’t throw \nit (but it’s really an egg), it doesn’t matter.  Consequences of \na Type I error are costlier, so they’ll want to minimize fp.\n\n95\n\nhttps://towardsdatascience.com/false-positives-vs-false-negatives-4184c2ff941a\n \n\nhttps://www.reddit.com/r/mildlyinteresting/com\nments/5uvn8r/i_collect_rocks_that_look_like_\neggs/","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":95,"lines":{"from":1,"to":25}}}},{"pageContent":"False positives or false negatives?\n\n96\n\nhttps://www.reddit.com/r/mildlyinteresting/com\nments/5uvn8r/i_collect_rocks_that_look_like_\neggs/\n \n\nTrue positive\n\nCorrect prediction\n\nFalse negative\n\n(kids’ model predicts rock so it \ndoesn’t get thrown, but it’s \nactually just an egg)\n\nFalse positive\n\n(kids’ model predicts \negg, so it’ll get thrown, \nbut it’s actually a rock!)\n\nTrue negative\n\nCorrect prediction\n\n     \n\n \nModel predicts...\n\n\nEgg\n\n\n\n\n\nRock\n\nTrue Value \n         \n\nRock\n\n\nEgg","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":96,"lines":{"from":1,"to":50}}}},{"pageContent":"False positives or false negatives?\n\n97\n\nhttps://www.reddit.com/r/mildlyinteresting/com\nments/5uvn8r/i_collect_rocks_that_look_like_\neggs/\n \n\nTrue positive\n\nCorrect prediction\n\nFalse negative\n\n(kids’ model predicts rock so it \ndoesn’t get thrown, but it’s \nactually just an egg)\n\nFalse positive\n\n(kids’ model predicts \negg, so it’ll get thrown, \nbut it’s actually a rock!)\n\nTrue negative\n\nCorrect prediction\n\n     \n\n \nModel predicts...\n\n\nEgg\n\n\n\n\n\nRock\n\nTrue Value \n         \n\nRock\n\n\nEgg\n\nThis is the most \ndangerous case!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":97,"lines":{"from":1,"to":53}}}},{"pageContent":"●\nThe kids discover that the neighborhood egg \nstash contains some golden eggs.  They use the \nsame “egg classifier” for whether an egg-shaped \nitem is an egg (egg=1, potentially high $ value) or \na rock (egg=0, definitely $0).\n\n\n○\nDo the kids care more about fp or fn?\n\n98\n\nhttps://towardsdatascience.com/false-positives-vs-false-negatives-4184c2ff941a\n \n\nhttps://www.increasemyefficiency.com/how-\nto-build-a-golden-egg/\n \n\nFalse positives or false negatives?\n\n琀\n琀\n \n\ntp\n\nfn\n\nfp\n\ntn\n\n   \nŷ\n=1      \nŷ\n=0\n\n y=0     y=1","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":98,"lines":{"from":1,"to":41}}}},{"pageContent":"False positives or false negatives?\n\n●\nThe kids discover that the neighborhood egg \nstash contains some golden eggs.  They use the \nsame “egg classifier” for whether an egg-shaped \nitem is an egg (egg=1, potentially high $ value) or \na rock (egg=0, definitely $0).\n\n○\nIf the kids think something is an egg but it’s actually a rock, \nthat’s okay – they just get $0 out of it. If they think \nsomething is a rock but it’s really a $$$ golden egg, they’re \nmissing out on a ton of money.  Consequences of a Type II \nerror are costlier, so they’ll want to minimize fn.\n\n99\n\nhttps://towardsdatascience.com/false-positives-vs-false-negatives-4184c2ff941a\n \n\nhttps://www.increasemyefficiency.com/how-\nto-build-a-golden-egg/","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":99,"lines":{"from":1,"to":23}}}},{"pageContent":"False positives or false negatives?\n\n100\n\nTrue positive\n\nCorrect prediction\n\nFalse negative\n\n(kids’ model predicts rock so \nthey don’t try to cash it in, but \nit’s actually worth $$$!)\n\nFalse positive\n\n(kids’ model predicts egg, \nso they try to cash it in, but \nit’s only worth $0)\n\nTrue negative\n\nCorrect prediction\n\n     \n\n \nModel predicts...\n\n\nEgg\n\n\n\n\n\nRock\n\nTrue Value \n         \n\nRock\n\n\nEgg\n\nhttps://www.increasemyefficiency.com/how-\nto-build-a-golden-egg/","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":100,"lines":{"from":1,"to":48}}}},{"pageContent":"False positives or false negatives?\n\n101\n\n     \n\n \nModel predicts...\n\n\nEgg\n\n\n\n\n\nRock\n\nTrue Value \n         \n\nRock\n\n\nEgg\n\nThis is the worst \ncase!\n\nhttps://www.increasemyefficiency.com/how-\nto-build-a-golden-egg/\n \n\nTrue positive\n\nCorrect prediction\n\nFalse negative\n\n(kids’ model predicts rock so \nthey don’t try to cash it in, but \nit’s actually worth $$$!)\n\nFalse positive\n\n(kids’ model predicts egg, \nso they try to cash it in, but \nit’s only worth $0)\n\nTrue negative\n\nCorrect prediction","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":101,"lines":{"from":1,"to":52}}}},{"pageContent":"https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n \n\n(Lots of options for classification)\n\n102","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":102,"lines":{"from":1,"to":6}}}},{"pageContent":"Evaluating with accuracy\n\n●\nAccuracy\n \n= (tp + tn) / (p + n) \n\n\n\n      = % things you predicted correctly\n\n\n●\nSeems intuitive...\n\n\n●\nBut rarely used in ML.  Why not?\n\n103","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":103,"lines":{"from":1,"to":20}}}},{"pageContent":"●\ny = 1 if someone has an extremely rare \ndisease (with 1% incidence in your dataset)\n\n\n●\nYou make a naive model that simply \npredicts y = 0 for every single input x\n\n\n●\nWhat accuracy would you get with this \nnaive model?\n \nAccuracy\n \n= (tp + tn) / (p + n) \n\n104\n\n琀\n琀\n \n\nEvaluating with accuracy","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":104,"lines":{"from":1,"to":25}}}},{"pageContent":"●\ny = 1 if someone has an extremely rare \ndisease (with 1% incidence in your dataset)\n\n\n●\nYou make a naive model that simply \npredicts y = 0 for every single input x\n\n\n●\nYour naive model would get 99% \naccuracy. \n \nThis isn’t useful for what matters: making \ngood predictions even if there are only a \nfew true y = 1 values.\n\n105\n\nEvaluating with accuracy","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":105,"lines":{"from":1,"to":21}}}},{"pageContent":"106\n\nhttps://www.facebook.com/AnalyticsVidhya/pho\ntos/a.457177331040819/2826021784156350/?\ntype=3","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":106,"lines":{"from":1,"to":5}}}},{"pageContent":"True positive\n\nCorrect prediction\n\nFalse negative\n\n\nFalse positive\n\nTrue negative\n\nCorrect prediction\n\n      Model predicts 1\n\n      \n\n     \n\nModel predicts 0\n\n          True value is 0\n\n True value is 1\n\n107\n\nBinary classification outcomes","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":107,"lines":{"from":1,"to":28}}}},{"pageContent":"Binary evaluation metrics, part 1\n\n●\nPrecision\n = tp / (tp + fp)\n\n\n●\nRecall\n \n(a.k.a. sensitivity) \n= tp / (tp + fn)\n\n\n●\nHigher is better!\n\n108","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":108,"lines":{"from":1,"to":18}}}},{"pageContent":"109\n\nhttps://levity.ai/blog/precision-vs-recall","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":109,"lines":{"from":1,"to":3}}}},{"pageContent":"Precision, Recall\n\nhttps://en.wikipedia.org/wiki/Precision_and_recall\n \n\n110","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":110,"lines":{"from":1,"to":6}}}},{"pageContent":"Precision, Recall\n\nhttps://en.wikipedia.org/wiki/Precision_and_recall\n \n\n111\n\nTrue \n1’s","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":111,"lines":{"from":1,"to":9}}}},{"pageContent":"Precision, Recall\n\nhttps://en.wikipedia.org/wiki/Precision_and_recall\n \n\n112\n\nTrue \n0’s","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":112,"lines":{"from":1,"to":9}}}},{"pageContent":"Precision, Recall\n\nhttps://en.wikipedia.org/wiki/Precision_and_recall\n \n\n113\n\nPredicted 1’s","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":113,"lines":{"from":1,"to":8}}}},{"pageContent":"Precision, Recall\n\nhttps://en.wikipedia.org/wiki/Precision_and_recall\n \n\n114\n\nHow many of your \npredicted y=1’s were \ncorrectly predicted?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":114,"lines":{"from":1,"to":10}}}},{"pageContent":"Precision, Recall\n\nhttps://en.wikipedia.org/wiki/Precision_and_recall\n \n\n115\n\nIf you always predict y=0, \nyou get undefined precision","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":115,"lines":{"from":1,"to":9}}}},{"pageContent":"Precision, Recall\n\nhttps://en.wikipedia.org/wiki/Precision_and_recall\n \n\n116\n\nHow many of the true \ny=1’s were correctly \npredicted?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":116,"lines":{"from":1,"to":10}}}},{"pageContent":"Precision, Recall\n\nhttps://en.wikipedia.org/wiki/Precision_and_recall\n \n\n117\n\nIf you always predict y=0, \nyou get 0 recall","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":117,"lines":{"from":1,"to":9}}}},{"pageContent":"Precision, Recall\n\nhttps://en.wikipedia.org/wiki/Precision_and_recall\n \n\n118\n\nHigher is better for both \nprecision and recall","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":118,"lines":{"from":1,"to":9}}}},{"pageContent":"Can you get high precision AND recall?\n\nhttps://en.wikipedia.org/wiki/Precision_and_recall\n \n\n119\n\nPredicted 1’s","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":119,"lines":{"from":1,"to":8}}}},{"pageContent":"Can you get high precision AND recall?\n\nhttps://en.wikipedia.org/wiki/Precision_and_recall\n \n\n120\n\nThere’s a trade-off","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":120,"lines":{"from":1,"to":8}}}},{"pageContent":"Precision and Recall\n\n●\nPrecision\n = tp / (tp + fp)\n\n\n\n\n●\nRecall\n = tp / (tp + fn)\n\n\n\n121\n\ntp\n\nfn\n\nfp\n\ntn\n\n   \nŷ\n=1      \nŷ\n=0\n\n y=0     y=1\n\ntp\n\nfn\n\nfp\n\ntn\n\n   \nŷ\n=1      \nŷ\n=0\n\n y=0     y=1","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":121,"lines":{"from":1,"to":48}}}},{"pageContent":"Calculate precision, recall, accuracy\n\n●\nPrecision\n = tp / (tp + fp)\n\n\n●\nRecall\n = tp / (tp + fn)\n\n\n●\nAccuracy\n \n\n= (tp + tn) / (tp + fp + fn + tn) \n\n\n\n\n122\n\ntp\n\n40\n\nfn\n\n10\n\nfp\n\n10\n\ntn\n\n40\n\n   \nŷ\n=1      \nŷ\n=0\n\n y=0      y=1\n\n琀\n琀","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":122,"lines":{"from":1,"to":49}}}},{"pageContent":"123\n\ntp\n\n40\n\nfn\n\n10\n\nfp\n\n10\n\ntn\n\n40\n\n   \nŷ\n=1      \nŷ\n=0\n\n y=0      y=1\n\nPrecision = 4/5 \n\nRecall = 4/5\n\nAccuracy = 4/5\n\n●\nPrecision\n = tp / (tp + fp)\n\n\n●\nRecall\n = tp / (tp + fn)\n\n\n●\nAccuracy\n \n\n= (tp + tn) / (tp + fp + fn + tn) \n\n\n\n\nCalculate precision, recall, accuracy","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":123,"lines":{"from":1,"to":52}}}},{"pageContent":"124\n\ntp\n\n4\n\nfn\n\n1\n\nfp\n\n5\n\ntn\n\n90\n\n   \nŷ\n=1      \nŷ\n=0\n\n y=0     y=1\n\n●\nPrecision\n = tp / (tp + fp)\n\n\n●\nRecall\n = tp / (tp + fn)\n\n\n●\nAccuracy\n \n\n= (tp + tn) / (tp + fp + fn + tn) \n\n\n\n\nCalculate precision, recall, accuracy\n\n琀\n琀","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":124,"lines":{"from":1,"to":49}}}},{"pageContent":"125\n\ntp\n\n4\n\nfn\n\n1\n\nfp\n\n5\n\ntn\n\n90\n\n   \nŷ\n=1      \nŷ\n=0\n\n y=0     y=1\n\nPrecision = 4/9 \n\nRecall = 4/5\n\nAccuracy = 94/100\n\n●\nPrecision\n = tp / (tp + fp)\n\n\n●\nRecall\n = tp / (tp + fn)\n\n\n●\nAccuracy\n \n\n= (tp + tn) / (tp + fp + fn + tn) \n\n\n\n\nCalculate precision, recall, accuracy","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":125,"lines":{"from":1,"to":52}}}},{"pageContent":"126\n\ntp\n\n0\n\nfn\n\n5\n\nfp\n\n0\n\ntn\n\n95\n\n   \nŷ\n=1      \nŷ\n=0\n\n y=0     y=1\n\n●\nPrecision\n = tp / (tp + fp)\n\n\n●\nRecall\n = tp / (tp + fn)\n\n\n●\nAccuracy\n \n\n= (tp + tn) / (tp + fp + fn + tn) \n\n\n\n\nCalculate precision, recall, accuracy\n\n琀\n琀","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":126,"lines":{"from":1,"to":49}}}},{"pageContent":"127\n\ntp\n\n0\n\nfn\n\n5\n\nfp\n\n0\n\ntn\n\n95\n\n   \nŷ\n=1      \nŷ\n=0\n\n y=0     y=1\n\nPrecision = NaN \n\nRecall = 0\n\nAccuracy = 95/100\n\n●\nPrecision\n = tp / (tp + fp)\n\n\n●\nRecall\n = tp / (tp + fn)\n\n\n●\nAccuracy\n \n\n= (tp + tn) / (tp + fp + fn + tn) \n\n\n\n\nCalculate precision, recall, accuracy","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":127,"lines":{"from":1,"to":52}}}},{"pageContent":"128\n\ntp\n\n4\n\nfn\n\n1\n\nfp\n\n5\n\ntn\n\n9000\n\n   \nŷ\n=1      \nŷ\n=0\n\n y=0     y=1\n\n●\nPrecision\n = tp / (tp + fp)\n\n\n●\nRecall\n = tp / (tp + fn)\n\n\n●\nAccuracy\n \n\n= (tp + tn) / (tp + fp + fn + tn) \n\n\n\n\nCalculate precision, recall, accuracy\n\n琀\n琀","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":128,"lines":{"from":1,"to":49}}}},{"pageContent":"129\n\ntp\n\n4\n\nfn\n\n1\n\nfp\n\n5\n\ntn\n\n9000\n\n   \nŷ\n=1      \nŷ\n=0\n\n y=0     y=1\n\nPrecision = 4/9 \n\nRecall = 4/5\n\nAccuracy = 9004/9010\n\n●\nPrecision\n = tp / (tp + fp)\n\n\n●\nRecall\n = tp / (tp + fn)\n\n\n●\nAccuracy\n \n\n= (tp + tn) / (tp + fp + fn + tn) \n\n\n\n\nCalculate precision, recall, accuracy","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":129,"lines":{"from":1,"to":52}}}},{"pageContent":"Reminder: Extra Credit!\n \n\n\n\n●\nTwo surveys, +10 points towards HW2 grade \nfor filling out each:\n\n\n○\nMid-Semester Course Feedback\n\n\n○\nMidterm TA Evaluations\n\n\n●\nSurveys due on Oct 13\n\n\n130","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":130,"lines":{"from":1,"to":23}}}},{"pageContent":"Prelim Grades will be released on Gradescope\n\n131","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":131,"lines":{"from":1,"to":3}}}},{"pageContent":"Prelim Grades will be released on Gradescope\n\n132\n\n“Curve”: everyone will get \n[\ngradescope\n]*0.8+22.5 points\n\n→\n 84.9\n\n→\n 103.7","metadata":{"source":"docs/INFO_2950/INFO2950_Lec13_20231011.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224502"},"metadata":null,"totalPages":132},"loc":{"pageNumber":132,"lines":{"from":1,"to":14}}}}]