[{"pageContent":"INFO 2950: \n\nIntro to Data Science\n\n\nLecture 25\n\n2023-11-27\n\n1","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":1,"lines":{"from":1,"to":10}}}},{"pageContent":"Agenda\n\n1.\nClassification\n\na.\nLinear separability\n\n\n2.\nContinuous output prediction\n\na.\nLinear Regression\n\nb.\nPerceptrons\n\nc.\nNeural Networks\n\n\n\n\n2","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":2,"lines":{"from":1,"to":25}}}},{"pageContent":"Classifying\n\n●\nTo classify data (e.g., to predict whether binary \noutput y is 0 or 1), we’ve learned how to use:\n\n\n○\n(Logistic) regression\n\n○\nNaive Bayes\n\n○\nK-means clustering\n\n\n\n3","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":3,"lines":{"from":1,"to":19}}}},{"pageContent":"Linear separability\n\nGiven bill length and depth, can you draw a \nline that reliably separates \nAdelie\n \npenguins from \nChinstrap\n and \nGentoo\n \npenguins?\n\n4","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":4,"lines":{"from":1,"to":14}}}},{"pageContent":"Linear separability\n\nGiven bill length and depth, can you draw a \nline that reliably separates \nAdelie\n \npenguins from \nChinstrap\n and \nGentoo\n \npenguins?\n\nYes! It's not perfect, but most of the blue \ndots (\nAdelie\n) are on one side, and most of \nthe non-blue dots are on the other\n\n5","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":5,"lines":{"from":1,"to":20}}}},{"pageContent":"Regression = Decision boundary\n\nMath version:\n\nα\n = 25\n\nβ\nlength\n = -1.5, \nβ\ndepth\n = 2.0\n\n\nClassification:\n\ny = 1 if Adelie, 0 if Chinstrap, 0 if Gentoo\n\n6","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":6,"lines":{"from":1,"to":20}}}},{"pageContent":"Calculate a linear output\n\nMath version:\n\nα\n = 25\n\nβ\nlength\n = -1.5, \nβ\ndepth\n = 2.0\n\nIs the value for length=40, depth=20 \npositive or negative?\n\n7\n\n琀\n琀","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":7,"lines":{"from":1,"to":21}}}},{"pageContent":"Calculate a linear output\n\nMath version:\n\nα\n = 25\n\nβ\nlength\n = -1.5, \nβ\ndepth\n = 2.0\n\nIs the value for length=40, depth=20 \npositive or negative?\n\n25 + (-60) + 40 = 5 \npositive\n\n8","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":8,"lines":{"from":1,"to":21}}}},{"pageContent":"Calculate a linear output\n\nMath version:\n\nα\n = 25\n\nβ\nlength\n = -1.5, \nβ\ndepth\n = 2.0\n\nIs the value for length=40, depth=15 \npositive or negative?\n\n\n9\n\n琀\n琀","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":9,"lines":{"from":1,"to":22}}}},{"pageContent":"Calculate a linear output\n\nMath version:\n\nα\n = 25\n\nβ\nlength\n = -1.5, \nβ\ndepth\n = 2.0\n\nIs the value for length=40, depth=15 \npositive or negative?\n\n25 + (-60) + 30 = -5 \nnegative\n\n10","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":10,"lines":{"from":1,"to":21}}}},{"pageContent":"Regions of positive / negative\n\nMath version:\n\nα\n = 25\n\nβ\nlength\n = -1.5, \nβ\ndepth\n = 2.0\n\nApplying these weights for any point left \nof the line gives us a positive value, and \nany point right of the line negative\n\n\n11\n\n+\n\n-","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":11,"lines":{"from":1,"to":24}}}},{"pageContent":"logistic regression\n\nMath version:\n\nα\n = 25\n\nβ\nlength\n = -1.5, \nβ\ndepth\n = 2.0\n\nThe logistic function squashes negative \ntowards 0 and positive towards 1\n\n\n12\n\n1\n\n0","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":12,"lines":{"from":1,"to":23}}}},{"pageContent":"logistic regression\n\nMath version:\n\nα\n = 25\n\nβ\nlength\n = -1.5, \nβ\ndepth\n = 2.0\n\nThe logistic function squashes negative \ntowards 0 and positive towards 1\n\n\n13\n\n1\n\n0\n\nPlateaus of confidence\n\nCliff of uncertainty","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":13,"lines":{"from":1,"to":27}}}},{"pageContent":"logistic regression\n\nMath version:\n\nα\n = 25\n\nβ\nlength\n = -1.5, \nβ\ndepth\n = 2.0\n\nThe logistic function squashes negative \ntowards 0 and positive towards 1\n\n\n14\n\n1\n\n0\n\nArts quad          West campus\n\nLibe slope","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":14,"lines":{"from":1,"to":27}}}},{"pageContent":"Three views of Log. Reg.\n\nMathematical expression\n\ny = \nσ\n(\nα\n + \nβ\nlength\n X\nlength\n + \nβ\ndepth\n X\ndepth\n)\n\nPython object\n\n   \nadelie_model.coef_, adelie_model.intercept_\n\n(array([[-1.37,  1.98]]), array([24.29]))\n\n\n15\n\n1\n\n0","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":15,"lines":{"from":1,"to":33}}}},{"pageContent":"A visual language for regression\n\nThe \ninputs\n (length and \ndepth) feed into the output \n(is the penguin Adelie?)\n\nEach input has a \nweight\n\nThe output has a \nbias\n or \nintercept\n\n16\n\nlength\n\ndepth\n\nis Adelie?\n\n-1.5\n\n  2.0\n\n25","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":16,"lines":{"from":1,"to":29}}}},{"pageContent":"A visual language for regression\n\n\"To guess if a penguin is an \nAdelie, take -1.5 times the \nbill length plus 2.0 times the \nbill depth, and add 25. If the \nresult is positive, guess yes \n(1), otherwise guess no (0)\"\n\n17\n\nlength\n\ndepth\n\nis Adelie?\n\n-1.5\n\n  2.0\n\n25","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":17,"lines":{"from":1,"to":22}}}},{"pageContent":"Linear separability\n\nGiven bill length and depth, can you draw a \nline that reliably separates \nGentoo\n \npenguins from \nChinstrap\n and \nAdelie\n \npenguins?\n\n18","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":18,"lines":{"from":1,"to":14}}}},{"pageContent":"Linear separability\n\nMath version:\n\nα\n = 28\n\nβ\nlength\n = 0.5, \nβ\ndepth\n = -3.0\n\nIs the value for length=40, depth=15 \npositive or negative?\n\n\n19\n\n琀\n琀","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":19,"lines":{"from":1,"to":22}}}},{"pageContent":"Linear separability\n\nMath version:\n\nα\n = 28\n\nβ\nlength\n = 0.5, \nβ\ndepth\n = -3.0\n\nIs the value for length=40, depth=15 \npositive or negative?\n\n28 + 20 - 45 = 3 \npositive\n\n20","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":20,"lines":{"from":1,"to":21}}}},{"pageContent":"Regions of positive and negative\n\nMath version:\n\nα\n = 28\n\nβ\nlength\n = 0.5, \nβ\ndepth\n = -3.0\n\nIs the value for length=40, depth=15 \npositive or negative?\n\n28 + 20 - 45 = 3 \npositive\n\n21\n\n+\n\n-","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":21,"lines":{"from":1,"to":25}}}},{"pageContent":"A visual language for regression\n\nThe \ninputs\n (length and \ndepth) feed into the output \n(is the penguin Adelie?)\n\nEach input has a \nweight\n\nThe output has a \nbias\n or \nintercept\n\n22\n\nlength\n\ndepth\n\nis Gentoo?\n\n0.5\n\n-3.0\n\n28","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":22,"lines":{"from":1,"to":29}}}},{"pageContent":"A visual language for regression\n\nWe can create more than \none regression model from \nthe same data!\n\nThis is equivalent to \ndrawing two decision \nboundaries\n\n23\n\nlength\n\ndepth\n\nis Adelie?\n\n-1.5\n\n  2.0\n\n25\n\nis Gentoo?\n\n28\n\n  0.5\n\n-3.0","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":23,"lines":{"from":1,"to":31}}}},{"pageContent":"Linear separability\n\nGiven bill length and depth, can you draw a \nline that reliably separates \nChinstrap\n \npenguins from \nGentoo\n and \nAdelie\n \npenguins?\n\n24","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":24,"lines":{"from":1,"to":14}}}},{"pageContent":"Linear separability\n\nGiven bill length and depth, can you draw a \nline that reliably separates \nChinstrap\n \npenguins from \nGentoo\n and \nAdelie\n \npenguins?\n\nNot really, no\n\n25","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":25,"lines":{"from":1,"to":16}}}},{"pageContent":"Outputs as inputs\n\nIf we combine the output of two linear \nclassifiers, we can identify a non-linear \nregion!\n\n26","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":26,"lines":{"from":1,"to":7}}}},{"pageContent":"Multiple layers of regression\n\nOutputs from layer 1 \nbecome inputs to layer 2\n\n27\n\nlength\n\ndepth\n\nis Adelie?\n\n-1.5\n\n  2.0\n\n25\n\nis Gentoo?\n\n28\n\n  0.5\n\n-3.0\n\nis Chinstrap?\n\n-1\n\n-1\n\n  0.5","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":27,"lines":{"from":1,"to":34}}}},{"pageContent":"Classifying\n\n●\nTo classify data (e.g., to predict whether binary \noutput y is 0 or 1), we’ve learned how to use:\n\n\n○\n(Logistic) regression\n\n○\nNaive Bayes\n\n○\nK-means clustering\n\n\n\n28","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":28,"lines":{"from":1,"to":19}}}},{"pageContent":"Classifying\n\n●\nTo classify data (e.g., to predict whether binary \noutput y is 0 or 1), we’ve learned how to use:\n\n\n○\n(Logistic) regression\n\n○\nNaive Bayes\n\n○\nK-means clustering\n\n\n●\nWhat if we have \ncontinuous\n output y?\n\n29\n\n琀\n琀","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":29,"lines":{"from":1,"to":26}}}},{"pageContent":"Classifying\n\n●\nTo classify data (e.g., to predict whether binary \noutput y is 0 or 1), we’ve learned how to use:\n\n\n○\n(Logistic) regression\n\n○\nNaive Bayes\n\n○\nK-means clustering\n\n\n●\nWhat if we have \ncontinuous\n output y? We can \nuse\n linear regression!\n\n30","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":30,"lines":{"from":1,"to":25}}}},{"pageContent":"Predicting continuous data\n\n●\nWe know we can do the following things with \nlinear regressions:\n\n\n○\nPredict\n (continuous) outputs\n\n○\nSummarize\n relationships between input \nand output variables\n\n○\nDescribe outliers/oddities\n\n31","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":31,"lines":{"from":1,"to":20}}}},{"pageContent":"Predicting continuous data\n\n●\nWe know we can do the following things with \nlinear regressions:\n\n\n○\nPredict\n (continuous) outputs\n\n○\nSummarize\n relationships between input \nand output variables\n\n○\nDescribe outliers/oddities\n\n32\n\nWhat if we can get \nmore \naccurate predictions","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":32,"lines":{"from":1,"to":24}}}},{"pageContent":"Predicting continuous data\n\n●\nWe know we can do the following things with \nlinear regressions:\n\n\n○\nPredict\n (continuous) outputs\n\n○\nSummarize\n relationships between input \nand output variables\n\n○\nDescribe outliers/oddities\n\n33\n\nWhat if we can get \nmore \naccurate predictions\n\nIn exchange for \nless \ninterpretable results?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":33,"lines":{"from":1,"to":28}}}},{"pageContent":"Neural networks!\n\n●\nNeural nets are \nmodels\n: \n\n○\nStill have multiple inputs\n x\ni\n \nand make a \nsingle prediction \nŷ\n\n○\nStill train on \ntrain_set\n and test on \ntest_set\n\n\n\n34","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":34,"lines":{"from":1,"to":25}}}},{"pageContent":"Neural networks!\n\n●\nNeural nets are \nmodels\n: \n\n○\nStill have multiple inputs\n x\ni\n \nand make a \nsingle prediction \nŷ\n\n○\nStill train on \ntrain_set\n and test on \ntest_set\n\n\n\n35\n\nNote: this prediction \ncan be classification \nOR continuous","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":35,"lines":{"from":1,"to":29}}}},{"pageContent":"Neural networks!\n\n●\nNeural nets are \nmodels\n: \n\n○\nStill have multiple inputs\n x\ni\n \nand make a \nsingle prediction \nŷ\n\n○\nStill train on \ntrain_set\n and test on \ntest_set\n\n\n●\nBut, neural nets often outperform linear \nregressions on \nbig data\n because they can \naccount for \nnonlinearities\n\n36","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":36,"lines":{"from":1,"to":32}}}},{"pageContent":"37\n\nhttps://www.emergingtechbrew.com/stories/2022/02/16/the-creator-of-the-viral\n-neural-net-guesses-memes-twitter-account-explains-how-it-works\n \n\nNeural nets work \npretty well, but \nthey aren’t \nperfect!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":37,"lines":{"from":1,"to":10}}}},{"pageContent":"A simple neural net (NN)\n\n38\n\nhttps://en.wikipedia.org/wiki/Neural_network","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":38,"lines":{"from":1,"to":5}}}},{"pageContent":"A simple neural net (NN)\n\n39\n\nhttps://en.wikipedia.org/wiki/Neural_network\n \n\nx\n1\n\nx\n2","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":39,"lines":{"from":1,"to":12}}}},{"pageContent":"A simple neural net (NN)\n\n40\n\nhttps://en.wikipedia.org/wiki/Neural_network\n \n\nEach circle is a \n“node” with an \ninput and an \noutput","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":40,"lines":{"from":1,"to":11}}}},{"pageContent":"A simple neural net (NN)\n\n41\n\nhttps://en.wikipedia.org/wiki/Neural_network\n \n\nŷ","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":41,"lines":{"from":1,"to":8}}}},{"pageContent":"A \ndeep\n neural net (NN)\n\n42\n\nhttps://www.ibm.com/cloud/learn/neural-networks","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":42,"lines":{"from":1,"to":7}}}},{"pageContent":"Neural networks for big data\n\n43\n\nhttps://joonatan.medium.com/most-important-concepts-in-applied-machine-learning-11e1e5f33ff4","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":43,"lines":{"from":1,"to":5}}}},{"pageContent":"Neural networks for big data\n\n44\n\nhttps://joonatan.medium.com/most-important-concepts-in-applied-machine-learning-11e1e5f33ff4\n \n\nSmall data: linear \nregression works great!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":44,"lines":{"from":1,"to":9}}}},{"pageContent":"Neural networks for big data\n\n45\n\nhttps://joonatan.medium.com/most-important-concepts-in-applied-machine-learning-11e1e5f33ff4\n \n\nBig data: use neural nets!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":45,"lines":{"from":1,"to":8}}}},{"pageContent":"Neural networks for big data\n\n46\n\nhttps://joonatan.medium.com/most-important-concepts-in-applied-machine-learning-11e1e5f33ff4\n \n\nLots of layers can be effective...","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":46,"lines":{"from":1,"to":8}}}},{"pageContent":"47\n\nhttps://www.reddit.com/r/ProgrammerHumor/comments/8c1i45/stack_more_layers/","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":47,"lines":{"from":1,"to":3}}}},{"pageContent":"Neural net drawbacks\n\n●\nNeural nets are difficult for humans to interpret\n\n\n●\nNeural nets are prone to overfitting on small \ndata (needs big data to benefit from \nnonlinearities)\n\n\n●\nNeural nets require a lot of compute\n\n○\nGPUs, CPUs, distributed computing (work \nin parallel)\n\n48","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":48,"lines":{"from":1,"to":20}}}},{"pageContent":"Compute & sustainability\n\n●\n“\nTraining a single BERT base model (without \nhyperparameter tuning) on GPUs was estimated to \nrequire\n \nas much energy as a trans-American flight\n.\n”\n\n49\n\nhttps://dl.acm.org/doi/pdf/10.1145/3442188.3445922","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":49,"lines":{"from":1,"to":15}}}},{"pageContent":"What is a neural net?\n\n50\n\n●\nInspired by the human brain:\n\n\n○\nDifferent parts of the brain have different \nfunctions, which occur by firing neurons (10\n11\n)\n\n\n\nBased on slide by T. Finin, M. desJardins, L Getoor, R. Par\n\nhttps://www.seas.upenn.edu/~cis5190/fall2017/lectures/11_NeuralNets.pdf","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":50,"lines":{"from":1,"to":19}}}},{"pageContent":"What is a neural net?\n\n51\n\n●\nInspired by the human brain:\n\n\n○\nDifferent parts of the brain have different \nfunctions, which occur by firing neurons (10\n11\n)\n\n\n○\nWe don’t exactly know how different brain \nfunctions are assigned (hard to interpret!), but \nwe know neurons connect via synapses (10\n14\n)\n\n\n\nBased on slide by T. Finin, M. desJardins, L Getoor, R. Par\n\nhttps://www.seas.upenn.edu/~cis5190/fall2017/lectures/11_NeuralNets.pdf","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":51,"lines":{"from":1,"to":27}}}},{"pageContent":"What is a neural net?\n\n52\n\n●\nInspired by the human brain:\n\n\n○\nDifferent parts of the brain have different \nfunctions, which occur by firing neurons (10\n11\n)\n\n\n○\nWe don’t exactly know how different brain \nfunctions are assigned (hard to interpret!), but \nwe know neurons connect via synapses (10\n14\n)\n\n\n\nBased on slide by T. Finin, M. desJardins, L Getoor, R. Par\n\nhttps://www.seas.upenn.edu/~cis5190/fall2017/lectures/11_NeuralNets.pdf\n \n\nhttps://en.wikipedia.org/wiki/Neural_network","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":52,"lines":{"from":1,"to":30}}}},{"pageContent":"What is a neural net?\n\n53\n\n●\nInspired by the human brain:\n\n\n○\nDifferent parts of the brain have different \nfunctions, which occur by firing neurons (10\n11\n)\n\n\n○\nWe don’t exactly know how different brain \nfunctions are assigned (hard to interpret!), but \nwe know neurons connect via synapses (10\n14\n)\n\n\n○\nThe output is “consciousness”\n\nBased on slide by T. Finin, M. desJardins, L Getoor, R. Par","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":53,"lines":{"from":1,"to":27}}}},{"pageContent":"What is a neural net?\n\n54\n\n●\nInspired by the human brain:\n\n\n○\nDifferent parts of the brain have different \nfunctions, which occur by firing neurons (10\n11\n)\n\n\n○\nWe don’t exactly know how different brain \nfunctions are assigned (hard to interpret!), but \nwe know neurons connect via synapses (10\n14\n)\n\n\n○\nThe output is “consciousness”\n\nBased on slide by T. Finin, M. desJardins, L Getoor, R. Par\n\nComputers: “only” \n10\n9 \ngates, 10\n9 \n bits \nRAM. Brain wins!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":54,"lines":{"from":1,"to":35}}}},{"pageContent":"Example: predicting house prices\n\n55\n\n●\nWhat are some input x’s that are useful to \npredict output y = house price?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":55,"lines":{"from":1,"to":7}}}},{"pageContent":"Example: predicting house prices\n\n56\n\n●\nWhat are some input x’s that are useful to \npredict output y = house price?\n\n○\nSquare footage\n\n○\n# bed, # bath\n\n○\nLocation\n\n○\nNeighborhood house $’s\n\n○\n...","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":56,"lines":{"from":1,"to":22}}}},{"pageContent":"Refresher: linear regression\n\n57\n\n●\nStep 1: decide on your inputs and outputs\n\n○\nPlot/summarize... \n\n■\nOutliers\n\n■\nCollinearity\n\n■\nMissing data","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":57,"lines":{"from":1,"to":18}}}},{"pageContent":"Refresher: linear regression\n\n58\n\n●\nStep 1: decide on your inputs and outputs\n\n○\nPlot/summarize... \n\n■\nOutliers\n\n■\nCollinearity\n\n■\nMissing data\n\n\nhttps://towardsdatascience.com/predicting-house-prices-with-linear-regression-machine-learning-from-scratch-part-ii-47a0238aeac1","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":58,"lines":{"from":1,"to":21}}}},{"pageContent":"Refresher: linear regression\n\n59\n\n●\nStep 2: perform data preprocessing\n\n■\nMissing values (imputation)\n\n■\nTransformations, normalization","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":59,"lines":{"from":1,"to":12}}}},{"pageContent":"Refresher: linear regression\n\n60\n\n●\nStep 2: perform data preprocessing\n\n■\nMissing values (imputation)\n\n■\nTransformations, normalization\n\nhttps://towardsdatascience.com/predicting-house-prices-with-linear-regression-machine-learning-from-scratch-part-ii-47a0238aeac1","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":60,"lines":{"from":1,"to":14}}}},{"pageContent":"Refresher: linear regression\n\n61\n\n●\nStep 2: perform data preprocessing\n\n■\nMissing values (imputation)\n\n■\nTransformations, normalization\n\nhttps://towardsdatascience.com/predicting-house-prices-with-linear-regression-machine-learning-from-scratch-part-ii-47a0238aeac1\n\nIn addition to having more easily \ncomparable coefficients, our \nalgorithms (SGD) converge faster \nwhen data is scaled!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":61,"lines":{"from":1,"to":19}}}},{"pageContent":"Refresher: linear regression\n\n62\n\n●\nStep 3: decide on an evaluation metric\n\n■\nChoose one based on data type of output y\n\n●\nFor housing prices: \n_______\n\n\n\nhttps://blog.jovian.ai/how-to-predict-housing-prices-with-linear-regression-b7c5a6fe1175\n \n\n琀\n琀","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":62,"lines":{"from":1,"to":21}}}},{"pageContent":"Refresher: linear regression\n\n63\n\n●\nStep 3: decide on an evaluation metric\n\n■\nChoose one based on data type of output y\n\n●\nFor housing prices: \nRMSE, MSE, MAE, \nMAPE, ... any evaluation metric that is \nreasonable for \ncontinuous output y\n\n\n\nhttps://blog.jovian.ai/how-to-predict-housing-prices-with-linear-regression-b7c5a6fe1175","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":63,"lines":{"from":1,"to":20}}}},{"pageContent":"Refresher: linear regression\n\n64\n\n●\nStep 3: decide on an evaluation metric\n\n■\nChoose one based on data type of output y\n\n●\nFor housing prices, maybe RMSE\n\n●\ndef\n \nrmse\n(\npredict,actual\n):\n\nreturn\n np.sqrt(np.mean(np.square(predict - \nactual)))\n\n\n\n\nhttps://blog.jovian.ai/how-to-predict-housing-prices-with-linear-regression-b7c5a6fe1175","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":64,"lines":{"from":1,"to":29}}}},{"pageContent":"Refresher: linear regression\n\n65\n\n●\nStep 3: decide on an evaluation metric\n\n■\nChoose one based on data type of output y\n\n●\nFor housing prices, maybe RMSE\n\n\n●\nStep 4: split your data\n\n■\nTrain / val / test sets\n\n■\nX_train,X_test,y_train,y_test \n=train_test_split(X,y,test_size=0.4)\n\n\nhttps://blog.jovian.ai/how-to-predict-housing-prices-with-linear-regression-b7c5a6fe1175","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":65,"lines":{"from":1,"to":26}}}},{"pageContent":"Refresher: linear regression\n\n66\n\n●\nStep 5: run a regression\n\n■\ny ~ x\n1 \n+ x\n2\n + x\n3\n\n\n\n\nhttps://towardsdatascience.com/predicting-house-prices-with-linear-regression-machine\n-learning-from-scratch-part-ii-47a0238aeac1\n \n\nDifferent notation: instead of \nβ\n’s for coefficients, we now \nuse \nw\n to represent “weights”","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":66,"lines":{"from":1,"to":28}}}},{"pageContent":"Refresher: linear regression\n\n67\n\n●\nStep 5: run a regression\n\n■\ny ~ x\n1 \n+ x\n2\n + x\n3\n + ...\n\n\nmodel=LinearRegression().fit(X_train,y_train)\n\npredictions_test=model.predict(X_test)\n\nrmse(predictions_test,y_test)\n\n\nhttps://blog.jovian.ai/how-to-predict-housing-prices-with-linear-regression-b7c5a6fe1175","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":67,"lines":{"from":1,"to":25}}}},{"pageContent":"Refresher: linear regression\n\n68\n\n●\nStep 5: run a regression\n\n■\ny ~ x\n1 \n+ x\n2\n + x\n3\n + ...\n\n\nmodel=LinearRegression().fit(X_train,y_train)\n\npredictions_test=model.predict(X_test)\n\nrmse(predictions_test,y_test)\n\n\n●\nStep 6: interpret results!\n\n○\nPredict, summarize, outliers/oddities\n\n\nhttps://blog.jovian.ai/how-to-predict-housing-prices-with-linear-regression-b7c5a6fe1175","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":68,"lines":{"from":1,"to":32}}}},{"pageContent":"Model Recap\n\n69\n\n\n\n○\nStep 1: decide on inputs / outputs\n\n○\nStep 2: data preprocessing\n\n○\nStep 3: decide on an evaluation metric\n\n○\nStep 4: split your data\n\n○\nStep 5: run the model\n\n○\nStep 6: interpret results","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":69,"lines":{"from":1,"to":23}}}},{"pageContent":"But what about neural nets?!\n\n70\n\n●\nA lot of these steps are the same!\n\n\n○\nStep 1: decide on inputs / outputs\n\n○\nStep 2: data preprocessing\n\n○\nStep 3: decide on an evaluation metric\n\n○\nStep 4: split your data\n\n○\nStep 5: run the model\n\n○\nStep 6: interpret results\n\nWe do this before even \ntouching linear regression \n/ neural nets!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":70,"lines":{"from":1,"to":29}}}},{"pageContent":"But what about neural nets?!\n\n71\n\n●\nA lot of these steps are the same!\n\n\n○\nStep 1: decide on inputs / outputs\n\n○\nStep 2: data preprocessing\n\n○\nStep 3: decide on an evaluation metric\n\n○\nStep 4: split your data\n\n○\nStep 5: run the model\n\n○\nStep 6: interpret results\n\nCaveat: more explanation \nneeded here","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":71,"lines":{"from":1,"to":28}}}},{"pageContent":"https://mimno.infosci.cornell.edu/info2950/interactive/wine.html\n \n\n72","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":72,"lines":{"from":1,"to":4}}}},{"pageContent":"Gradient is a hint in multiple \ndirections\n\nThe slope is steep in the \nEast-West direction, \n\nbut flat in the \nNorth-South direction\n\n73","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":73,"lines":{"from":1,"to":10}}}},{"pageContent":"74","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":74,"lines":{"from":1,"to":1}}}},{"pageContent":"Stochastic Gradient Descent (SGD)\n\nDerivative is \nnegative, so we \nshould reduce \nx\n, \nbut how much?\n\n75\n\noutput \nf(x)\n\ninput x","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":75,"lines":{"from":1,"to":15}}}},{"pageContent":"SGD: move \nβ\n in a direction \nspecified by the gradient\n\nSlope still \nnegative, but \nless so:\n\n\n\"keep going in \nthat direction, \nbut slow down\"\n\n76\n\noutput \nf(x)\n\ninput x","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":76,"lines":{"from":1,"to":20}}}},{"pageContent":"SGD: \"step size\" or \"learning rate\" \n\nis important\n\nIf you take a big \nstep you may \novershoot:\n\n\n\"Whoa, too far! \nback up a bit\"\n\n77\n\noutput \nf(x)\n\ninput x","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":77,"lines":{"from":1,"to":18}}}},{"pageContent":"SGD: \"step size\" or \"learning rate\" \n\nis important\n\nOvershooting \ncan lead to \noscillation and \nblowup! \n\n\n78\n\noutput \nf(x)\n\ninput x","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":78,"lines":{"from":1,"to":16}}}},{"pageContent":"Too small a step \nand it will take \nforever to improve\n\nSGD: \"step size\" or \"learning rate\" \n\nis important\n\n79\n\noutput \nf(x)\n\ninput x","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":79,"lines":{"from":1,"to":14}}}},{"pageContent":"Step 3: decide on an evaluation metric\n\n80\n\n●\nIn machine learning, we use an algorithm (e.g. SGD) that \nsteps towards convergence and  “learns” when we’ve \nreached a local minimum\n\n○\n“Loss function” = how you evaluate when to stop \n\n○\nRMSE is one choice of loss function","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":80,"lines":{"from":1,"to":14}}}},{"pageContent":"Step 3: decide on an evaluation metric\n\n81\n\n●\nIn machine learning, we use an algorithm (e.g. SGD) that \nsteps towards convergence and  “learns” when we’ve \nreached a local minimum\n\n\nLoss Function (e.g. RMSE)\n\nhttps://medium.com/@ben_lau93/house-prices-prediction-using-andrew-ngs-machine-learning-algorithm-31b29a81acb8","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":81,"lines":{"from":1,"to":13}}}},{"pageContent":"Step 3: decide on an evaluation metric\n\n82\n\n●\nIn Step 5, we’ve used sklearn to run: \n\nmodel=LinearRegression().fit(X_train,y_train)\n\n\n●\nBut, we can re-define “fit” to include things like...\n\n\n\ndef fit(self, X, y, n_iter=100000, lr=0.01):\n\n\n# [gradient descent code that runs for \nn_iter\n iterations and \n\n# uses \nlr\n learning rate step sizes]\n\n\nreturn self\n\nhttps://towardsdatascience.com/predicting-house-prices-with-linear-regression-machine-learning-from-scratch-part-ii-47a0238aeac1","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":82,"lines":{"from":1,"to":30}}}},{"pageContent":"Step 3: decide on an evaluation metric\n\n83\n\n●\nIn Step 5, we’ve used sklearn to run: \n\nmodel=LinearRegression().fit(X_train,y_train)\n\n\n●\nBut, we can re-define “fit” to include things like...\n\n\n\ndef fit(self, X, y, n_iter=100000, lr=0.01):\n\n\n# [gradient descent code that runs for \nn_iter\n iterations and \n\n# uses \nlr\n learning rate step sizes]\n\n\nreturn self\n\nhttps://towardsdatascience.com/predicting-house-prices-with-linear-regression-machine-learning-from-scratch-part-ii-47a0238aeac1\n \n\nmodel=LinearRegression().fit(X_train,y_train, 2000, 0.01)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":83,"lines":{"from":1,"to":33}}}},{"pageContent":"Step 3: decide on an evaluation metric\n\n84\n\n●\nYour loss should be smoothly converging to a local min\n\n●\nDebug by checking for NaNs or repeated input data, \nchanging learning rate, etc. if you see plots like:\n\nhttps://developers.google.com/machine-learning/testing-debugging/metrics/interpretic\n \n\nbad!\n\nbad!\n\nbad!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":84,"lines":{"from":1,"to":19}}}},{"pageContent":"Step 3: decide on an evaluation metric\n\n85\n\n●\nIt’s important to check the loss for each of your train / val / \ntest sets separately, to ensure no overfitting is happening!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":85,"lines":{"from":1,"to":7}}}},{"pageContent":"Step 3: decide on an evaluation metric\n\n86\n\n●\nIt’s important to check the loss for each of your train / val / \ntest sets separately, to ensure no overfitting is happening!\n\nhttps://developers.google.com/machine-learning/testing-debugging/metrics/interpretic\n \n\nIs this indicative \nof overfitting?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":86,"lines":{"from":1,"to":13}}}},{"pageContent":"Step 3: decide on an evaluation metric\n\n87\n\n●\nIt’s important to check the loss for each of your train / val / \ntest sets separately, to ensure no overfitting is happening!\n\nhttps://developers.google.com/machine-learning/testing-debugging/metrics/interpretic\n \n\nThis is overfit! \nWe’re performing \nway better on train \nthan test! (We want \nto \nminimize\n loss)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":87,"lines":{"from":1,"to":18}}}},{"pageContent":"But what about neural nets?!\n\n88\n\n●\nA lot of these steps are the same!\n\n\n○\nStep 1: decide on inputs / outputs\n\n○\nStep 2: data preprocessing\n\n○\nStep 3: decide on an evaluation metric\n\n○\nStep 4: split your data\n\n○\nStep 5: run the model\n\n○\nStep 6: interpret results\n\nSpecifically, make sure \nyou have code to plot \nloss function","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":88,"lines":{"from":1,"to":29}}}},{"pageContent":"But what about neural nets?!\n\n89\n\n●\nA lot of these steps are the same!\n\n\n○\nStep 1: decide on inputs / outputs\n\n○\nStep 2: data preprocessing\n\n○\nStep 3: decide on an evaluation metric\n\n○\nStep 4: split your data\n\n○\nStep 5: run the model\n\n○\nStep 6: interpret results\n\nHow do we do this with \nneural nets?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":89,"lines":{"from":1,"to":28}}}},{"pageContent":"1 min break & attendance!\n\n90\n\ntinyurl.com/7haktr95","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":90,"lines":{"from":1,"to":5}}}},{"pageContent":"But what about neural nets?!\n\n91\n\n●\nA lot of these steps are the same!\n\n\n○\nStep 1: decide on inputs / outputs\n\n○\nStep 2: data preprocessing\n\n○\nStep 3: decide on an evaluation metric\n\n○\nStep 4: split your data\n\n○\nStep 5: run the model\n\n○\nStep 6: interpret results\n\nHow do we do this with \nneural nets?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":91,"lines":{"from":1,"to":28}}}},{"pageContent":"Perceptron\n\n92\n\nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n“activation \nfunction”","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":92,"lines":{"from":1,"to":9}}}},{"pageContent":"Perceptron (Minsky-Papert, 1969)\n\n93\n\nhttps://www.codecademy.com/learn/perceptrons-and-neural-nets-skill-path/modules/perceptrons-skill-path/cheatsheet","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":93,"lines":{"from":1,"to":5}}}},{"pageContent":"Single-layer perceptron\n\n94\n\nhttps://en.wikipedia.org/wiki/Neural_network\n \n\nEach circle is a \n“node” with an \ninput","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":94,"lines":{"from":1,"to":10}}}},{"pageContent":"Single-layer perceptron\n\n\n95\n\nhttps://en.wikipedia.org/wiki/Neural_network\n \n\nEach circle is a \n“node” with an \ninput and an \noutput","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":95,"lines":{"from":1,"to":12}}}},{"pageContent":"Single-layer perceptron\n\n\n96\n\nhttps://en.wikipedia.org/wiki/Neural_network\n \n\nEach node also \nhas a \ncorresponding \nweight\n and \nbias","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":96,"lines":{"from":1,"to":14}}}},{"pageContent":"Single-layer perceptron\n\n\n97\n\nhttps://en.wikipedia.org/wiki/Neural_network\n \n\nEach node also \nhas a \ncorresponding \nweight\n and \nbias\n\ncoefficient\n\nintercept","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":97,"lines":{"from":1,"to":18}}}},{"pageContent":"Single-layer perceptron\n\n\n98\n\nhttps://en.wikipedia.org/wiki/Neural_network\n \n\nThink of each \nnode as its own \nlinear regression","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":98,"lines":{"from":1,"to":11}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n99\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":99,"lines":{"from":1,"to":8}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n100\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\nweights","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":100,"lines":{"from":1,"to":11}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n101\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\nweights\n\nactivation \nfunctions","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":101,"lines":{"from":1,"to":14}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n102\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\nhttp://hyperphysics.phy-astr.gsu.edu/hbase/Electronic/xor.html","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":102,"lines":{"from":1,"to":11}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n103\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n1\n\n1","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":103,"lines":{"from":1,"to":13}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n104\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n1\n\n1\n\n1*1","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":104,"lines":{"from":1,"to":15}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n105\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n1\n\n1\n\n1*1\n\n1*1","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":105,"lines":{"from":1,"to":17}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n106\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n1\n\n1\n\n1*1\n\n1*1+1*1\n\n1*1","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":106,"lines":{"from":1,"to":19}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n107\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n1\n\n1\n\n1*1\n\n1*1\n\nTRUE \n(1>.5)\n\nTRUE\n\n(1>.5)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":107,"lines":{"from":1,"to":24}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n108\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n1\n\n1\n\n1*1\n\n1*1+1*1\n\n1*1\n\nTRUE \n(1>.5)\n\nTRUE (2 > 1.5)\n\nTRUE\n\n(1>.5)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":108,"lines":{"from":1,"to":28}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n109\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n1\n\n1\n\nTRUE\n\nTRUE\n\nTRUE","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":109,"lines":{"from":1,"to":19}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n110\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n1\n\n1\n\n1\n\n1\n\n1","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":110,"lines":{"from":1,"to":19}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n111\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n1\n\n1\n\n1\n\n1\n\n1\n\n琀\n琀\n \n\nWhat value do \nwe compare to \n.5?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":111,"lines":{"from":1,"to":27}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n112\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n1\n\n1\n\n1\n\n1\n\n1\n\n1*1-2*1+1*1 = 0","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":112,"lines":{"from":1,"to":21}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n113\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n1\n\n1\n\n1\n\n1\n\n1\n\n1*1-2*1+1*1\n\nFALSE (0 < .5)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":113,"lines":{"from":1,"to":23}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n114\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n1\n\n1\n\n1\n\n1\n\n1\n\n1*1-2*1+1*1\n\nFALSE (0 < .5)\n\nhttp://hyperphysics.phy-astr.gsu.edu/hbase/Electronic/xor.html","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":114,"lines":{"from":1,"to":25}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n115\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n1\n\n1\n\n1\n\n1\n\n1\n\nThis works! So, we \nmultiply weights \nwith inputs, and \nthen sum:\n\nhttp://hyperphysics.phy-astr.gsu.edu/hbase/Electronic/xor.html\n \n\n1*1-2*1+1*1 = \nΣ\nw\ni\nx\ni","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":115,"lines":{"from":1,"to":34}}}},{"pageContent":"Multi-layer perceptron: XOR, \n1985\n\n\n116\n\nRumelhart, Hinton & Williams. \nhttps://www.diva-portal.org/smash/get/diva2:1304961/FULLTEXT01.pdf\n \n\n1\n\n1\n\n1\n\n1\n\n1\n\nHow did we know to \ncompare \nΣ\nw\ni\nx\ni \nto \n\n> .5 or > 1.5?\n\n\n\n\n\nRemember, the \ncircles are called \nactivation functions\n\nhttp://hyperphysics.phy-astr.gsu.edu/hbase/Electronic/xor.html","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":116,"lines":{"from":1,"to":40}}}},{"pageContent":"Common activation functions\n\n117\n\nhttps://www.codecademy.com/learn/perceptrons-and-neural-nets-skill-path/modules/perceptrons-skill-path/cheatsheet\n\nhttps://en.wikipedia.org/wiki/Heaviside_step_function\n \n  \n\nStep function: f(x) =","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":117,"lines":{"from":1,"to":11}}}},{"pageContent":"Common activation functions\n\n118\n\nhttps://www.codecademy.com/learn/perceptrons-and-neural-nets-skill-path/modules/perceptrons-skill-path/cheatsheet\n\nhttps://en.wikipedia.org/wiki/Heaviside_step_function\n \n  \n\nStep function: f(x) = \n\n>\n\n\n≤\n\n(We compared \nΣ\nw\ni\nx\ni\n\nto being over/under .5 or 1.5 \ninstead of over/under 0, which \nis just shifting a step function!)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":118,"lines":{"from":1,"to":27}}}},{"pageContent":"Common activation functions\n\n119\n\nhttps://www.codecademy.com/learn/perceptrons-and-neural-nets-skill-path/modules/perceptrons-skill-path/cheatsheet\n\nhttps://paperswithcode.com/method/relu\n \n \n\nRectified Linear \nUnits\n (\nReLUs):","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":119,"lines":{"from":1,"to":14}}}},{"pageContent":"Common activation functions\n\n120\n\nhttps://www.codecademy.com/learn/perceptrons-and-neural-nets-skill-path/modules/perceptrons-skill-path/cheatsheet\n \n\nLeaky ReLU:\n\nhttps://production-media.paperswithcode.com/methods/new_act.jpg","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":120,"lines":{"from":1,"to":10}}}},{"pageContent":"Common activation functions\n\n121\n\nhttps://www.codecademy.com/learn/perceptrons-and-neural-nets-skill-path/modules/perceptrons-skill-path/cheatsheet\n \n\nWhat’s this \nfunction called?\n\n琀\n琀","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":121,"lines":{"from":1,"to":12}}}},{"pageContent":"Common activation functions\n\n122\n\nhttps://www.codecademy.com/learn/perceptrons-and-neural-nets-skill-path/modules/perceptrons-skill-path/cheatsheet\n \n\nAndrew Ng, \nhttps://slideplayer.com/slide/12620833/76/","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":122,"lines":{"from":1,"to":9}}}},{"pageContent":"Common activation functions\n\n123\n\nhttps://paperswithcode.com/method/tanh-activation\n \n\nHyperbolic tangent (Tanh) \nlooks like sigmoid, but goes \nfrom -1 to 1 instead of 0 to 1.","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":123,"lines":{"from":1,"to":10}}}},{"pageContent":"Neural nets\n\n124\n\n●\nNNs are just multi-layer perceptrons!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":124,"lines":{"from":1,"to":6}}}},{"pageContent":"Neural nets\n\n125\n\n●\nNNs are just multi-layer perceptrons!\n\n\n●\nHow do you get weight and bias values?\n\n○\nSimilar to regressions: “training the model” results in a \nweight (coefficient) and bias (intercept) for each node","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":125,"lines":{"from":1,"to":14}}}},{"pageContent":"Neural nets\n\n126\n\n●\nNNs are just multi-layer perceptrons!\n\n\n●\nHow do you get weight and bias values?\n\n○\nSimilar to regressions: “training the model” results in a \nweight (coefficient) and bias (intercept) for each node\n\n○\nRandomly initialize your weights.  Iterate:\n\n■\nGradient descent\n: finds where to minimize loss \nfunction\n\n■\nBackpropagation\n: updates weights based on \ngradient of loss","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":126,"lines":{"from":1,"to":27}}}},{"pageContent":"Interpreting neural nets\n\n127\n\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/discussion/111538","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":127,"lines":{"from":1,"to":5}}}},{"pageContent":"Interpreting neural nets\n\n128\n\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/discussion/111538\n \n\nInput (x’s): \nknown","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":128,"lines":{"from":1,"to":9}}}},{"pageContent":"Interpreting neural nets\n\n129\n\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/discussion/111538\n \n\nOutput (\nŷ\n)","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":129,"lines":{"from":1,"to":10}}}},{"pageContent":"Interpreting neural nets\n\n130\n\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/discussion/111538\n \n\nHidden layer: unknown!\n\nWe’re just guessing the meanings of each node","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":130,"lines":{"from":1,"to":10}}}},{"pageContent":"Neural net layers\n\n131\n\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/discussion/111538\n \n\nHidden layer: unknown!\n\nWe’re just guessing the meanings of each node\n\n*Similar to how we had to guess \nconcepts for SVD decompositions; in \npractice this is much harder for NNs","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":131,"lines":{"from":1,"to":14}}}},{"pageContent":"Neural net hidden layer\n\n132\n\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/discussion/111538\n \n\nWhat we have control over: # hidden layers, # neurons \nin each layer, and what “activation” each layer uses","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":132,"lines":{"from":1,"to":9}}}},{"pageContent":"Neural net hidden layer\n\n133\n\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/discussion/111538\n \n\nWhat we have control over: # hidden layers, # neurons \nin each layer, and what “activation” each layer uses\n\n“Neural net \narchitecture”","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":133,"lines":{"from":1,"to":12}}}},{"pageContent":"Neural net hidden layer\n\n134\n\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/discussion/111538\n \n\nWhat we have control over: # hidden layers, # neurons \nin each layer, and what “activation” each layer uses\n\nShould always be \nreported in your \nresearch for \nreproducibility!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":134,"lines":{"from":1,"to":14}}}},{"pageContent":"135\n\nSlide from Andrew Ng \nhttps://slideplayer.com/slide/12620833/76/","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":135,"lines":{"from":1,"to":4}}}},{"pageContent":"MNIST data\n\n136\n\nhttps://www.kaggle.com/code/mommermi/mnist-neural-network-visualization","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":136,"lines":{"from":1,"to":5}}}},{"pageContent":"Which neurons are triggered?\n\n137\n\nhttps://www.kaggle.com/code/mommermi/mnist-neural-network-visualization","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":137,"lines":{"from":1,"to":5}}}},{"pageContent":"Which neurons are triggered?\n\n138\n\nhttps://www.kaggle.com/code/mommermi/mnist-neural-network-visualization\n \n\nYellow = more important\n\nBlue = less important","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":138,"lines":{"from":1,"to":10}}}},{"pageContent":"Which neurons are triggered?\n\n139\n\nhttps://www.kaggle.com/code/mommermi/mnist-neural-network-visualization\n \n\nThe “important” \nneurons are different \nfor different inputs!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":139,"lines":{"from":1,"to":10}}}},{"pageContent":"Which neurons are triggered?\n\n140\n\nhttps://www.kaggle.com/code/mommermi/mnist-neural-network-visualization\n \n\nWe can’t really tell \nwhat each hidden \nlayer’s “concept” is, \nbut we tell the NN is \nusing them to \ncorrectly noticed \nthat 5!=6","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":140,"lines":{"from":1,"to":14}}}},{"pageContent":"141\n\nhttps://programmerhumor.io/programming-memes/neural-networks-are-difficult/\n \n\nMy dumb neural net:","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":141,"lines":{"from":1,"to":6}}}},{"pageContent":"How do we do this in Python?\n\n●\nMore libraries!\n\n○\nTensorflow (v1 and v2)\n\n○\nKeras\n\n○\nJax\n\n○\nPyTorch\n\n○\nTheano\n\n142","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":142,"lines":{"from":1,"to":21}}}},{"pageContent":"Running neural nets\n\n143\n\n●\nA lot of these steps are the same!\n\n\n○\nStep 1: decide on inputs / outputs\n\n○\nStep 2: data preprocessing\n\n○\nStep 3: decide on an evaluation metric\n\n○\nStep 4: split your data\n\n○\nStep 5: run the model\n\n○\nStep 6: interpret results\n\nnumpy, scipy, \nscikit-learn, etc.\n\nCan use, e.g., Keras","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":143,"lines":{"from":1,"to":30}}}},{"pageContent":"E.g., in Keras:\n\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import Dense, Activation\n\nfrom tensorflow.keras.optimizers import Adam\n\n\n144\n\nImport relevant \npackages\n\nhttps://towardsdatascience.com/house-prices-prediction-using-deep-learning-dea265cc3154","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":144,"lines":{"from":1,"to":15}}}},{"pageContent":"E.g., in Keras:\n\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import Dense, Activation\n\nfrom tensorflow.keras.optimizers import Adam\n\n\n145\n\nImport relevant \npackages\n\nDeal with your NN architecture\n\nDeals with gradient descent\n\nhttps://towardsdatascience.com/house-prices-prediction-using-deep-learning-dea265cc3154","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":145,"lines":{"from":1,"to":19}}}},{"pageContent":"E.g., in Keras:\n\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import Dense, Activation\n\nfrom tensorflow.keras.optimizers import Adam\n\n\nmodel = Sequential()\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(1))model.compile(optimizer='Adam',loss='mes')\n\n\n146\n\nDefine NN\n\nhttps://towardsdatascience.com/house-prices-prediction-using-deep-learning-dea265cc3154","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":146,"lines":{"from":1,"to":27}}}},{"pageContent":"E.g., in Keras:\n\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import Dense, Activation\n\nfrom tensorflow.keras.optimizers import Adam\n\n\nmodel = Sequential()\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(1))model.compile(optimizer='Adam',loss='mes')\n\n\n147\n\nDefine NN\n\nAdd 4 hidden \nlayers, each with \n19 neurons and \nReLU activation \nfunction\n\nhttps://towardsdatascience.com/house-prices-prediction-using-deep-learning-dea265cc3154","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":147,"lines":{"from":1,"to":33}}}},{"pageContent":"E.g., in Keras:\n\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import Dense, Activation\n\nfrom tensorflow.keras.optimizers import Adam\n\n\nmodel = Sequential()\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(1))model.compile(optimizer='Adam',loss='mes')\n\n\n148\n\nDefine NN\n\nAdd output layer \n(final single \nneuron)\n\nhttps://towardsdatascience.com/house-prices-prediction-using-deep-learning-dea265cc3154","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":148,"lines":{"from":1,"to":31}}}},{"pageContent":"E.g., in Keras:\n\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import Dense, Activation\n\nfrom tensorflow.keras.optimizers import Adam\n\n\nmodel = Sequential()\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(19,activation='relu'))\n\nmodel.add(Dense(1))model.compile(optimizer='Adam',loss='mse')\n\n\n149\n\nDefine NN\n\nAdd output layer \n(final single \nneuron)\n\nDefine loss function\n\nhttps://towardsdatascience.com/house-prices-prediction-using-deep-learning-dea265cc3154","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":149,"lines":{"from":1,"to":33}}}},{"pageContent":"E.g., in Keras:\n\nmodel.fit(x=X_train,y=y_train,\n\n         validation_data=(X_test,y_test),\n\n         batch_size=128,epochs=400)\n\nmodel.summary()\n\n150\n\nhttps://towardsdatascience.com/house-prices-prediction-using-deep-learning-dea265cc3154\n \n\nFit the model by taking \n\"batches\" of 128 data \nrows at a time, \nsweeping over the full \ndata set 400 times \n(\"epochs\")","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":150,"lines":{"from":1,"to":21}}}},{"pageContent":"E.g., in Keras:\n\nloss_df = pd.DataFrame(model.history.history)\n\nloss_df.plot(figsize=(12,8))\n\n\n151\n\nhttps://towardsdatascience.com/house-prices-prediction-using-deep-learning-dea265cc3154\n \n\nPlot loss over epochs","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":151,"lines":{"from":1,"to":13}}}},{"pageContent":"E.g., in Keras:\n\ny_pred = model.predict(X_test)\n\n\nfrom sklearn import metrics\n\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred)) \n\nprint('MSE:', metrics.mean_squared_error(y_test, y_pred)) \n\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n\nprint('VarScore:',metrics.explained_variance_score(y_test,y_pred))\n\n\n\n152\n\nhttps://towardsdatascience.com/house-prices-prediction-using-deep-learning-dea265cc3154\n \n\nPredict y-hats\n\nUse sklearn to check evaluation metrics","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":152,"lines":{"from":1,"to":25}}}},{"pageContent":"Interpret: Regression vs. NN\n\n153\n\nhttps://towardsdatascience.com/house-prices-prediction-using-deep-learning-dea265cc3154\n \n\nWhich is better?\n\n\nNote: “Variance score” \nrefers to “explained \nvariance \nscore” (similar to R\n2\n)\n\nModel: Keras Neural Net\n\nModel: Sklearn Multiple Linear Regression\n\n琀\n琀","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":153,"lines":{"from":1,"to":23}}}},{"pageContent":"Interpret: Regression vs. NN\n\n154\n\nhttps://towardsdatascience.com/house-prices-prediction-using-deep-learning-dea265cc3154\n \n\nModel: Keras Neural Net\n\nModel: Sklearn Multiple Linear Regression\n\nLower error and \nhigher explainability \nis better!","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":154,"lines":{"from":1,"to":14}}}},{"pageContent":"Make sure to think about the broader \nimplications of a poorly-performing model!\n\n155\n\nhttps://journeys.dartmouth.edu/folklorearchive/2020/06/03/title-ai-cant-classify-a-cat/\n \n\nPeople with no idea \nabout AI, telling me my AI \nwill destroy the world\n\nMe wondering why my \nneural network is \nclassifying a cat as a dog...","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":155,"lines":{"from":1,"to":15}}}},{"pageContent":"“Parameters” in machine learning\n\n●\nModel \nparameters\n are the \nɑ\n/\nβ\ns/weights that are \nassigned to each variable\n\n○\nThese are internally set through the model’s learning \nprocess \n\n\n156","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":156,"lines":{"from":1,"to":18}}}},{"pageContent":"“Parameters” in machine learning\n\n●\nModel \nparameters\n are the \nɑ\n/\nβ\ns/weights that are \nassigned to each variable\n\n○\nThese are internally set through the model’s learning \nprocess \n\n●\nHyperparameters\n \nare specific model settings\n\n○\nThese are established prior to model \nlearning/training\n\n○\nHyperparameters do not change during model \ntraining; they guide training\n\n157","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":157,"lines":{"from":1,"to":30}}}},{"pageContent":"Hyperparameters\n\n●\nHyperparameters are the \narguments\n you can pass into a \nmodel when instantiating it \n\n\n●\nThere can be \nmany\n hyperparameters for a single model\n\n\n\n158","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":158,"lines":{"from":1,"to":17}}}},{"pageContent":"Hyperparameters\n\n●\nHyperparameters are the \narguments\n you can pass into a \nmodel when instantiating it \n\n\n●\nThere can be \nmany\n hyperparameters for a single model\n\n\n●\nChoosing the best hyperparameters is an important part \nof the machine learning process\n\n\n●\nDifferent hyperparameters can affect each other\n\n○\nSort of like interaction effects, but with model \nperformance!\n\n159","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":159,"lines":{"from":1,"to":28}}}},{"pageContent":"Hyperparameters\n\n●\nHyperparameters are the \narguments\n you can pass into a \nmodel when instantiating it \n\n\n●\nThere can be \nmany\n hyperparameters for a single model\n\n\n●\nChoosing the best hyperparameters is an important part \nof the machine learning process\n\n\n●\nDifferent hyperparameters can affect each other\n\n○\nSort of like interaction effects, but with model \nperformance!\n\n160\n\nCan you think of any \nhyperparameters \nwe’ve already \nencountered?","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":160,"lines":{"from":1,"to":33}}}},{"pageContent":"Output: k-means clustering\n\n161\n\nK=3","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":161,"lines":{"from":1,"to":5}}}},{"pageContent":"Examples of hyperparameters\n\n●\nK-Means Clustering:\n\n○\nNumber of clusters\n\n○\nclustering = KMeans(\nn_clusters=5\n)\n\n●\nTF-IDF\n\n○\nMax/min number of documents a word can appear in\n\n○\ntfidf_vectorizer = TfidfVectorizer(\nmin_df=5\n)\n\n●\nSGD\n\n○\nLearning rate\n\n●\nNeural networks\n\n○\nModel architecture (hidden layers, nodes, etc.)\n\n162","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":162,"lines":{"from":1,"to":37}}}},{"pageContent":"Examples of hyperparameters\n\n●\nK-Means Clustering:\n\n○\nNumber of clusters\n\n○\nclustering = KMeans(\nn_clusters=5\n)\n\n●\nTF-IDF\n\n○\nMax/min number of documents a word can appear in\n\n○\ntfidf_vectorizer = TfidfVectorizer(\nmin_df=5\n)\n\n●\nSGD\n\n○\nLearning rate\n\n●\nNeural networks\n\n○\nModel architecture (hidden layers, nodes, etc.)\n\n163\n\nHow do we choose \nthese numbers??\n\n\nThe best \nhyperparameter \nvalues vary based \non model,  dataset, \nand evaluation \nmetric","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":163,"lines":{"from":1,"to":48}}}},{"pageContent":"Hyperparameter tuning\n\n●\nWe always want to have the best-performing model\n\n\n●\nHow do we choose the hyperparameters that will \n“\noptimize\n” performance? \n\n\n○\nOne option: manually choose a combination of a \nfew hyperparameters and then see which model \nperforms best\n\n164\n\nhttps://twitter.com/mlinterview/status/993257627244204032","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":164,"lines":{"from":1,"to":21}}}},{"pageContent":"Hyperparameter tuning\n\n●\nWe always want to have the best-performing model\n\n\n●\nHow do we choose the hyperparameters that will \n“\noptimize\n” performance? \n\n\n○\nOne option: manually choose a combination of a \nfew hyperparameters and then see which model \nperforms best\n\n\n○\nBetter option: \nalgorithmically “search” for best \ncombinations of hyperparameters \n\n165\n\nhttps://twitter.com/mlinterview/status/993257627244204032","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":165,"lines":{"from":1,"to":27}}}},{"pageContent":"Hyperparameter tuning\n\n●\nBetter option:\n \nalgorithmically “search” for best \ncombinations of hyperparameters \n\n○\nThis is known as \nhyperparameter optimization\n \nor \nhyperparameter tuning\n\n\n●\nHyperparameter tuning tries various combinations of \nhyperparameters and how they affect model \nperformance \n\n166","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":166,"lines":{"from":1,"to":22}}}},{"pageContent":"Main steps of hyperparameter tuning\n\n1.\nChoose a model and a set of relevant hyperparameters\n\n\n\n167","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":167,"lines":{"from":1,"to":8}}}},{"pageContent":"Main steps of hyperparameter tuning\n\n1.\nChoose a model and a set of relevant hyperparameters\n\n\n2.\nDefine an evaluation function (like F1 or MSE)\n\n\n\n168","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":168,"lines":{"from":1,"to":12}}}},{"pageContent":"Main steps of hyperparameter tuning\n\n1.\nChoose a model and a set of relevant hyperparameters\n\n\n2.\nDefine an evaluation function (like F1 or MSE)\n\n\n3.\nIterate through hyperparameters\n\n\n\n169","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":169,"lines":{"from":1,"to":16}}}},{"pageContent":"Main steps of hyperparameter tuning\n\n1.\nChoose a model and a set of relevant hyperparameters\n\n\n2.\nDefine an evaluation function (like F1 or MSE)\n\n\n3.\nIterate through hyperparameters\n\n\n4.\nFor each combination of hyperparameter values, evaluate \nmodel performance (using step 2!)\n\n\n\n170","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":170,"lines":{"from":1,"to":21}}}},{"pageContent":"Main steps of hyperparameter tuning\n\n1.\nChoose a model and a set of relevant hyperparameters\n\n\n2.\nDefine an evaluation function (like F1 or MSE)\n\n\n3.\nIterate through hyperparameters\n\n\n4.\nFor each combination of hyperparameter values, evaluate \nmodel performance (using step 2!)\n\n\n5.\nSelect combination of hyperparameters that resulted in \nbest performance\n\n171","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":171,"lines":{"from":1,"to":24}}}},{"pageContent":"Main steps of hyperparameter tuning\n\n1.\nChoose a model and a set of relevant hyperparameters\n\n\n2.\nDefine an evaluation function (like F1 or MSE)\n\n\n3.\nIterate through hyperparameters\n\n\n4.\nFor each combination of hyperparameter values, evaluate \nmodel performance (using step 2!)\n\n\n5.\nSelect combination of hyperparameters that resulted in \nbest performance\n\n172","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":172,"lines":{"from":1,"to":24}}}},{"pageContent":"173\n\nMost common hyperparameter tuning \nprocedures:\n\n○\nGrid search:\n evaluate every \ncombination of hyperparameter \nvalues\n\n\n○\nRandom search: \nevaluate \nhyperparameter values drawn \nfrom a distribution\n\nhttps://medium.com/@senapati.dipak97/grid-search-vs-random-search-d34c92946318","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":173,"lines":{"from":1,"to":19}}}},{"pageContent":"Demo: Neural Network Playground\n\nhttps://playground.tensorflow.org/\n\n174","metadata":{"source":"docs/INFO_2950/INFO2950_Lec25_20231127 2.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.7","IsAcroFormPresent":false,"IsXFAPresent":false,"Creator":"PDFium","Producer":"PDFium","CreationDate":"D:20231206224256"},"metadata":null,"totalPages":174},"loc":{"pageNumber":174,"lines":{"from":1,"to":5}}}}]